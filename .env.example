# OpenAI API Key (Required)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Model Tier Configuration (Required)
# Controls which LLM models are used across the RAG pipeline
# Options: budget, balanced, premium
# - budget: All GPT-4o-mini ($1,200/day, 70-75% quality) - Showcases RAG architecture value
# - balanced: Hybrid GPT-4o-mini + GPT-5-mini ($1,800/day, 78-80% quality)
# - premium: GPT-5.1 + GPT-5-mini + GPT-5-nano ($12,060/day, 88-92% quality)
MODEL_TIER=budget

# HHEM Hallucination Detection Backend (Optional)
# Controls which backend is used for hallucination detection
# Options: local, vectara
# - local (default): Local HuggingFace model (HHEM-2.1-Open), works forever, no API keys needed
# - vectara: Vectara managed API (HHEM-2.3), faster (~200-500ms), requires API credentials
HHEM_BACKEND=local

# Vectara API Credentials (Required only if HHEM_BACKEND=vectara)
# Get your API key from: https://console.vectara.com/
# Note: Free trial (30 days, 10K credits), then paid
VECTARA_API_KEY=your-vectara-api-key-here
VECTARA_CUSTOMER_ID=your-vectara-customer-id-here

# LangSmith API Key (Optional - for tracing and monitoring)
# Get your API key from: https://smith.langchain.com/
LANGSMITH_API_KEY=your-langsmith-api-key-here

# LangSmith Project Name (Optional)
LANGSMITH_PROJECT=advanced-agentic-rag

# LangSmith Tracing (Optional - set to "true" to enable)
LANGSMITH_TRACING=false

# Redis Semantic Cache (Optional - caches answers for similar queries)
# Reduces latency from ~15s to ~50ms for repeated/similar questions
CACHE_ENABLED=false
REDIS_URL=redis://localhost:6379/0
CACHE_SIMILARITY_THRESHOLD=0.95
CORPUS_VERSION=v1
