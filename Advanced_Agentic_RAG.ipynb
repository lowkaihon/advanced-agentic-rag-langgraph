{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-1-intro",
   "metadata": {},
   "source": [
    "# Advanced Agentic RAG with LangGraph\n",
    "\n",
    "**A portfolio project showcasing intelligent, adaptive retrieval pipelines**\n",
    "\n",
    "This system demonstrates production-grade RAG architecture patterns:\n",
    "\n",
    "- **Dynamic strategy selection** - Semantic, keyword, or hybrid retrieval based on query analysis\n",
    "- **Quality-driven self-correction** - Automatic query rewrites when retrieval quality is insufficient\n",
    "- **Multi-stage reranking** - CrossEncoder (top-10) + LLM-as-judge (top-6) for precision\n",
    "- **NLI-based hallucination detection** - Claim decomposition with cross-encoder verification\n",
    "- **Multi-agent parallel retrieval** - Query decomposition with parallel workers for complex questions\n",
    "\n",
    "**Architecture**: 7-node StateGraph with distributed intelligence (no central orchestrator)  \n",
    "**Framework**: LangChain 1.0 & LangGraph 1.0  \n",
    "**Pattern**: Dynamic Planning and Execution Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:55:37.058491Z",
     "iopub.status.busy": "2025-11-27T07:55:37.058491Z",
     "iopub.status.idle": "2025-11-27T07:56:34.893409Z",
     "shell.execute_reply": "2025-11-27T07:56:34.891880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG variants loaded:\n",
      "  - basic_rag_graph: Simplest RAG (semantic search only)\n",
      "  - intermediate_rag_graph: Query expansion + hybrid + reranking\n",
      "  - advanced_rag_graph: Full agentic RAG with self-correction\n",
      "  - multi_agent_rag_graph: Parallel retrieval workers\n"
     ]
    }
   ],
   "source": [
    "# Setup & Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# All RAG graph variants\n",
    "from advanced_agentic_rag_langgraph.variants import (\n",
    "    basic_rag_graph,\n",
    "    intermediate_rag_graph,\n",
    "    advanced_rag_graph,\n",
    "    multi_agent_rag_graph,\n",
    ")\n",
    "from advanced_agentic_rag_langgraph.core import setup_retriever\n",
    "\n",
    "print(\"RAG variants loaded:\")\n",
    "print(\"  - basic_rag_graph: Simplest RAG (semantic search only)\")\n",
    "print(\"  - intermediate_rag_graph: Query expansion + hybrid + reranking\")\n",
    "print(\"  - advanced_rag_graph: Full agentic RAG with self-correction\")\n",
    "print(\"  - multi_agent_rag_graph: Parallel retrieval workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3-diagram",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:56:34.897447Z",
     "iopub.status.busy": "2025-11-27T07:56:34.897447Z",
     "iopub.status.idle": "2025-11-27T07:56:36.525070Z",
     "shell.execute_reply": "2025-11-27T07:56:36.524050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Architecture Diagram - LangGraph Mermaid Visualization\n",
    "from IPython.display import Image\n",
    "\n",
    "# Render the Advanced RAG graph structure\n",
    "Image(advanced_rag_graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4-routing",
   "metadata": {},
   "source": [
    "## Routing Logic (What the Diagram Doesn't Show)\n",
    "\n",
    "The graph visualization shows nodes and edges, but the **conditional routing logic** is where the \"intelligence\" lives:\n",
    "\n",
    "### `route_after_retrieval` - Quality-Based Branching\n",
    "```python\n",
    "if quality >= 0.6:\n",
    "    return \"answer_generation\"  # Good enough - proceed\n",
    "\n",
    "if attempts >= 2:\n",
    "    return \"answer_generation\"  # Max attempts - proceed anyway\n",
    "\n",
    "if (\"off_topic\" in issues or \"wrong_domain\" in issues) and (attempts == 1):\n",
    "    return \"query_expansion\"    # Early strategy switch\n",
    "else:\n",
    "    return \"rewrite_and_refine\" # Semantic rewrite\n",
    "```\n",
    "\n",
    "### `route_after_evaluation` - Answer Quality Gate\n",
    "```python\n",
    "if is_refusal:\n",
    "    return END  # LLM refused - terminal state\n",
    "\n",
    "if is_answer_sufficient:\n",
    "    return END\n",
    "\n",
    "if generation_attempts < 2:\n",
    "    return \"answer_generation\"  # Retry with feedback\n",
    "else:\n",
    "    return END  # Max attempts reached\n",
    "```\n",
    "\n",
    "### Key Design Principles\n",
    "- **Fix generation with generation** - Don't re-retrieve for generation problems\n",
    "- **Single correction cycle** - Research shows diminishing returns after first retry\n",
    "- **Adaptive thresholds** - Lower quality bar (50%) when retrieval is poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5-retriever",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:56:36.529086Z",
     "iopub.status.busy": "2025-11-27T07:56:36.529086Z",
     "iopub.status.idle": "2025-11-27T07:57:38.702131Z",
     "shell.execute_reply": "2025-11-27T07:57:38.700599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING ALL PDFS FROM docs/\n",
      "============================================================\n",
      "\n",
      "Found 10 PDF file(s):\n",
      "  1. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf (3.6 MB)\n",
      "  2. Attention Is All You Need.pdf (2.1 MB)\n",
      "  3. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf (0.7 MB)\n",
      "  4. Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf (30.1 MB)\n",
      "  5. Denoising Diffusion Probabilistic Models.pdf (9.8 MB)\n",
      "  6. Expanding Horizons in RAG - Exploring and Extending the Limits of RAPTOR.pdf (0.6 MB)\n",
      "  7. Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf (40.9 MB)\n",
      "  8. Improved Training of Wasserstein GANs.pdf (5.9 MB)\n",
      "  9. Learning Transferable Visual Models From Natural Language Supervision.pdf (6.5 MB)\n",
      "  10. U-Net - Convolutional Networks for Biomedical Image Segmentation.pdf (1.6 MB)\n",
      "\n",
      "============================================================\n",
      "STEP 1: Loading full documents (no chunking)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Loading 10 PDFs as full documents (no chunking)...\n",
      "Loading full document: AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pages: 22, Characters: 67,154\n",
      "Loading full document: Attention Is All You Need.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pages: 15, Characters: 39,511\n",
      "Loading full document: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf\n",
      "  Pages: 16, Characters: 64,131\n",
      "Loading full document: Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pages: 42, Characters: 97,294\n",
      "Loading full document: Denoising Diffusion Probabilistic Models.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pages: 25, Characters: 54,041\n",
      "Loading full document: Expanding Horizons in RAG - Exploring and Extending the Limits of RAPTOR.pdf\n",
      "  Pages: 11, Characters: 37,149\n",
      "Loading full document: Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pages: 27, Characters: 56,402\n",
      "Loading full document: Improved Training of Wasserstein GANs.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pages: 20, Characters: 41,584\n",
      "Loading full document: Learning Transferable Visual Models From Natural Language Supervision.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pages: 48, Characters: 224,303\n",
      "Loading full document: U-Net - Convolutional Networks for Biomedical Image Segmentation.pdf\n",
      "  Pages: 8, Characters: 19,623\n",
      "\n",
      "Loaded 10 full documents, 701,192 total characters\n",
      "\n",
      "============================================================\n",
      "STEP 2: Profiling documents with LLM\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "DOCUMENT PROFILING\n",
      "============================================================\n",
      "Profiling 10 documents...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 (doc_0):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, transformers, deep_learning\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2 (doc_1):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, deep_learning, nlp\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 3 (doc_2):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: nlp, transformers, deep_learning\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 4 (doc_3):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, generative_models, diffusion_models\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 5 (doc_4):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, deep_learning, computer_vision\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 6 (doc_5):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: nlp, retrieval_augmented_generation, machine_learning\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 7 (doc_6):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, machine_learning, generative_models\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 8 (doc_7):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, generative_adversarial_networks, deep_learning\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 9 (doc_8):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, natural_language_processing, machine_learning\n",
      "  Best Strategy: hybrid\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 10 (doc_9):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, deep_learning, biomedical_image_segmentation\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "============================================================\n",
      "CORPUS STATISTICS\n",
      "============================================================\n",
      "Total Documents: 10\n",
      "Average Technical Density: 0.86\n",
      "\n",
      "Document Types:\n",
      "  - conference_paper: 10 (100.0%)\n",
      "\n",
      "Domain Distribution:\n",
      "  - computer_vision: 5\n",
      "  - transformers: 2\n",
      "  - deep_learning: 6\n",
      "  - machine_learning: 7\n",
      "  - nlp: 3\n",
      "  - generative_models: 2\n",
      "  - diffusion_models: 1\n",
      "  - retrieval_augmented_generation: 1\n",
      "  - generative_adversarial_networks: 1\n",
      "  - natural_language_processing: 1\n",
      "  - biomedical_image_segmentation: 1\n",
      "\n",
      "Percentage with Code: 50.0%\n",
      "Percentage with Math: 70.0%\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "STEP 3: Chunking documents\n",
      "============================================================\n",
      "\n",
      "Created 924 chunks from 10 documents\n",
      "\n",
      "============================================================\n",
      "CORPUS STATISTICS\n",
      "============================================================\n",
      "Total documents: 10\n",
      "Total chunks: 924\n",
      "Avg technical density: 0.86\n",
      "Document types: {'conference_paper': 10}\n",
      "Has code: 50%\n",
      "Has math: 70%\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retriever initialized with 10 research papers (924 chunks)\n",
      "Papers include: Transformers, BERT, ViT, DDPM, CLIP, U-Net, WGAN-GP, Consistency Models\n"
     ]
    }
   ],
   "source": [
    "# Initialize Retriever (one-time setup)\n",
    "# This loads 10 research papers and creates the vector store\n",
    "setup_retriever()\n",
    "print(\"\\nRetriever initialized with 10 research papers (924 chunks)\")\n",
    "print(\"Papers include: Transformers, BERT, ViT, DDPM, CLIP, U-Net, WGAN-GP, Consistency Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6-tiers",
   "metadata": {},
   "source": [
    "## 4-Tier Architecture Comparison\n",
    "\n",
    "Each tier adds capabilities while using the **same budget model tier** (GPT-4o-mini) to isolate architectural improvements from model quality:\n",
    "\n",
    "| Tier | Features | Key Capabilities |\n",
    "|------|----------|------------------|\n",
    "| **Basic** | 1 | Semantic search only, direct LLM generation |\n",
    "| **Intermediate** | 5 | + Query expansion, hybrid retrieval, RRF fusion, reranking |\n",
    "| **Advanced** | 17 | + Strategy selection, quality gates, self-correction loops |\n",
    "| **Multi-Agent** | 20 | + Query decomposition, parallel workers, merge reranking |\n",
    "\n",
    "### Feature Progression\n",
    "- **Basic**: Pure semantic similarity - works well for simple, direct questions\n",
    "- **Intermediate**: Query variations improve recall, reranking improves precision\n",
    "- **Advanced**: Adapts strategy based on query type, retries on poor results\n",
    "- **Multi-Agent**: Decomposes complex questions, retrieves in parallel, merges results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7-comparison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:57:38.705124Z",
     "iopub.status.busy": "2025-11-27T07:57:38.705124Z",
     "iopub.status.idle": "2025-11-27T08:01:59.488551Z",
     "shell.execute_reply": "2025-11-27T08:01:59.487529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "================================================================================\n",
      "\n",
      "Running Basic RAG...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASIC RETRIEVAL\n",
      "Strategy: semantic only (vector similarity)\n",
      "Top-K: 4 chunks (no reranking)\n",
      "Retrieved: 4 documents\n",
      "\n",
      "All 4 chunk IDs (rank order):\n",
      "  1. Attention Is All You Need.pdf_chunk_10\n",
      "  2. Attention Is All You Need.pdf_chunk_17\n",
      "  3. Attention Is All You Need.pdf_chunk_8\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_36\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Answer length: 3715 chars\n",
      "Context docs: 4\n",
      "============================================================\n",
      "\n",
      "  Retrieval Quality: 0% | Groundedness: 0%\n",
      "\n",
      "Running Intermediate RAG...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY EXPANSION\n",
      "Original: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Generated 4 variations\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYBRID RETRIEVAL WITH RRF FUSION\n",
      "Strategy: hybrid (always)\n",
      "Query variants: 4\n",
      "Total retrievals: 48\n",
      "Unique docs after RRF: 19\n",
      "\n",
      "All 19 chunk IDs (RRF scores):\n",
      "  1. Attention Is All You Need.pdf_chunk_10 (0.0656)\n",
      "  2. Attention Is All You Need.pdf_chunk_17 (0.0640)\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_36 (0.0623)\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_13 (0.0618)\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_10 (0.0611)\n",
      "  6. Attention Is All You Need.pdf_chunk_8 (0.0609)\n",
      "  7. Attention Is All You Need.pdf_chunk_6 (0.0607)\n",
      "  8. Attention Is All You Need.pdf_chunk_11 (0.0446)\n",
      "  9. Attention Is All You Need.pdf_chunk_18 (0.0439)\n",
      "  10. Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf_chunk_28 (0.0421)\n",
      "  11. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_76 (0.0290)\n",
      "  12. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_12 (0.0288)\n",
      "  13. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_29 (0.0149)\n",
      "  14. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_71 (0.0143)\n",
      "  15. Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf_chunk_17 (0.0141)\n",
      "  16. Attention Is All You Need.pdf_chunk_23 (0.0141)\n",
      "  17. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_30 (0.0139)\n",
      "  18. Attention Is All You Need.pdf_chunk_29 (0.0139)\n",
      "  19. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_11 (0.0139)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CROSSENCODER RERANKING\n",
      "Input: 19 documents\n",
      "\n",
      "Chunk IDs sent to reranking (top-15):\n",
      "  1. Attention Is All You Need.pdf_chunk_10\n",
      "  2. Attention Is All You Need.pdf_chunk_17\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_36\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_13\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_10\n",
      "  6. Attention Is All You Need.pdf_chunk_8\n",
      "  7. Attention Is All You Need.pdf_chunk_6\n",
      "  8. Attention Is All You Need.pdf_chunk_11\n",
      "  9. Attention Is All You Need.pdf_chunk_18\n",
      "  10. Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf_chunk_28\n",
      "  ... and 5 more\n",
      "\n",
      "Output: 4 documents after CrossEncoder reranking\n",
      "\n",
      "Final chunk IDs (after CrossEncoder reranking):\n",
      "  1. Attention Is All You Need.pdf_chunk_10 (score: 3.7265)\n",
      "  2. Attention Is All You Need.pdf_chunk_18 (score: 2.0610)\n",
      "  3. Attention Is All You Need.pdf_chunk_11 (score: 0.8651)\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_13 (score: 0.2478)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Answer length: 3073 chars\n",
      "Context docs: 4\n",
      "============================================================\n",
      "\n",
      "  Retrieval Quality: 0% | Groundedness: 0%\n",
      "\n",
      "Running Advanced RAG...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY SELECTION\n",
      "Query: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Selected: SEMANTIC\n",
      "Confidence: 95%\n",
      "Reasoning: The user is seeking a detailed explanation of the forward pass through the Transformer encoder, which indicates a desire for conceptual understanding and an in-depth explanation of the components involved. This aligns with the semantic search strengths, as it can provide content that explains the 'how' and 'what' of the Transformer encoder's sub-layers and their connections. Exact matching is less critical here, as the user is looking for a comprehensive understanding rather than specific terms or identifiers. Given the technical nature of the corpus, which is focused on deep learning and transformers, a semantic approach will effectively retrieve relevant explanatory content.\n",
      "Note: Query optimization will happen in query_expansion_node\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Optimized query: Provide a detailed overview of the forward pass process within the Transformer encoder, highlighting the various sub-layers, their interconnections, and the underlying principles involved.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPANSION DECISION\n",
      "Query: Provide a detailed overview of the forward pass process within the Transformer encoder, highlighting the various sub-layers, their interconnections, and the underlying principles involved.\n",
      "LLM decision: EXPAND query\n",
      "Reasoning: The query is complex and involves multiple concepts related to the Transformer encoder, such as 'forward pass process', 'sub-layers', 'interconnections', and 'underlying principles'. Expanding this query into variations can help capture different terminologies and phrasing that users might employ when seeking information on this topic, thus improving retrieval effectiveness.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY EXPANDED\n",
      "Optimized query: Provide a detailed overview of the forward pass process within the Transformer encoder, highlighting the various sub-layers, their interconnections, and the underlying principles involved.\n",
      "Expansions: ['Explain the technical implementation of the forward pass in the Transformer encoder, detailing the sub-layers involved, their interconnections, and the mechanisms that drive their functionality.', 'Discuss the practical applications and use cases of the forward pass process in the Transformer encoder, emphasizing how its various sub-layers and connections contribute to real-world tasks.', 'Describe the underlying concepts and principles that govern the forward pass within the Transformer encoder, focusing on the relationships between sub-layers and the foundational ideas that support their operation.']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL EXECUTION START\n",
      "Using 4 query expansion(s)\n",
      "Expansions generated from: retrieval_query\n",
      "Retrieval strategy: semantic\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RRF MULTI-QUERY RETRIEVAL\n",
      "Query variants: 4\n",
      "Total retrievals: 60\n",
      "Unique docs after RRF: 20\n",
      "\n",
      "All 20 chunk IDs (RRF scores):\n",
      "  1. Attention Is All You Need.pdf_chunk_10 (0.0656)\n",
      "  2. Attention Is All You Need.pdf_chunk_17 (0.0638)\n",
      "  3. Attention Is All You Need.pdf_chunk_6 (0.0637)\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_36 (0.0623)\n",
      "  5. Attention Is All You Need.pdf_chunk_8 (0.0620)\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_13 (0.0604)\n",
      "  7. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_10 (0.0591)\n",
      "  8. Attention Is All You Need.pdf_chunk_5 (0.0574)\n",
      "  9. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_29 (0.0572)\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_71 (0.0558)\n",
      "  11. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_12 (0.0556)\n",
      "  12. Attention Is All You Need.pdf_chunk_18 (0.0441)\n",
      "  13. Attention Is All You Need.pdf_chunk_11 (0.0425)\n",
      "  14. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_11 (0.0409)\n",
      "  15. Attention Is All You Need.pdf_chunk_1 (0.0272)\n",
      "  16. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (0.0145)\n",
      "  17. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_35 (0.0137)\n",
      "  18. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_0 (0.0135)\n",
      "  19. Attention Is All You Need.pdf_chunk_0 (0.0133)\n",
      "  20. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_76 (0.0133)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TWO-STAGE RERANKING (After RRF)\n",
      "Input: 20 docs (from RRF top-40)\n",
      "\n",
      "Chunk IDs sent to reranking (top-40):\n",
      "  1. Attention Is All You Need.pdf_chunk_10\n",
      "  2. Attention Is All You Need.pdf_chunk_17\n",
      "  3. Attention Is All You Need.pdf_chunk_6\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_36\n",
      "  5. Attention Is All You Need.pdf_chunk_8\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_13\n",
      "  7. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_10\n",
      "  8. Attention Is All You Need.pdf_chunk_5\n",
      "  9. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_29\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_71\n",
      "  ... and 10 more\n",
      "\n",
      "============================================================\n",
      "RERANKING QUERY SOURCE\n",
      "Using: active_query (semantic, human-readable)\n",
      "Query: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Note: Reranking uses semantic query, NOT algorithm-optimized retrieval_query\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output: 4 docs after two-stage reranking\n",
      "\n",
      "Final chunk IDs (after two-stage reranking):\n",
      "  1. Attention Is All You Need.pdf_chunk_10 (score: 90.0000)\n",
      "  2. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_13 (score: 80.0000)\n",
      "  3. Attention Is All You Need.pdf_chunk_18 (score: 75.0000)\n",
      "  4. Attention Is All You Need.pdf_chunk_11 (score: 75.0000)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ROUTER: AFTER RETRIEVAL\n",
      "Quality: 70% (threshold: >=60%)\n",
      "Attempts: 1/2\n",
      "Issues: partial_coverage, missing_key_info\n",
      "Decision: answer_generation (quality acceptable)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Context size: 3524 chars\n",
      "Retrieval quality: 70%\n",
      "Generation attempt: 1/3\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 1\n",
      "Retrieval quality: 70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refusal detection: ATTEMPTED - The assistant provided a detailed explanation of the forward pass through the Transformer encoder, including the steps involved, the sub-layers, and their connections. Although it acknowledged limitations regarding specific mathematical formulations, it still offered substantive information about the encoder's structure and functioning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness: 88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 2/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Context size: 3524 chars\n",
      "Retrieval quality: 70%\n",
      "Generation attempt: 2/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "QUALITY ISSUES:\n",
      "Problems: partial_answer, missing_details\n",
      "Fix: Ensure all question parts are answered completely; Add more depth and explanation where the context provides supporting information\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 2\n",
      "Retrieval quality: 70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refusal detection: ATTEMPTED - The assistant provided a detailed explanation of the forward pass through the Transformer encoder, including all sub-layers and their connections. It described the input embedding, positional encoding, encoder structure, multi-head self-attention mechanism, position-wise feed-forward network, residual connections, layer normalization, and layer stacking. This response contains substantive information and does not reflect a refusal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness: 95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: END (max attempts reached)\n",
      "  Retrieval Quality: 70% | Groundedness: 95%\n",
      "\n",
      "Running Multi-Agent RAG...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPLEXITY CLASSIFICATION\n",
      "Query: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Classification: COMPLEX\n",
      "Reasoning: The query asks for a comprehensive explanation of the forward pass through the Transformer encoder, which involves multiple components (sub-layers) and their interactions. This requires understanding various aspects of the architecture, including attention mechanisms, normalization layers, and how they connect, making it a multi-faceted retrieval task.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY DECOMPOSITION (ORCHESTRATOR)\n",
      "Original: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Sub-queries (4):\n",
      "  1. What are the main components of the Transformer encoder architecture?\n",
      "  2. How does the self-attention mechanism work within the Transformer encoder?\n",
      "  3. What are the roles of the feed-forward neural network and layer normalization in the Transformer encoder?\n",
      "  4. How are the connections and data flow structured between the sub-layers in the Transformer encoder?\n",
      "Reasoning: The decomposition focuses on distinct aspects of the Transformer encoder's forward pass, ensuring each sub-query addresses a specific component or mechanism without relying on the others.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ASSIGN WORKERS (Send API)\n",
      "Spawning 4 parallel retrieval workers\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 0\n",
      "Sub-query: What are the main components of the Transformer encoder architecture?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 1\n",
      "Sub-query: How does the self-attention mechanism work within the Transformer encoder?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 2\n",
      "Sub-query: What are the roles of the feed-forward neural network and layer normalization in the Transformer encoder?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 3\n",
      "Sub-query: How are the connections and data flow structured between the sub-layers in the Transformer encoder?\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Worker] Strategy: semantic (90%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Worker] Strategy: semantic (90%)\n",
      "  [Worker] Strategy: semantic (90%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: What are the main components of the Transformer encoder architecture?\n",
      "Optimized query: What are the essential elements and principles that define the structure and functionality of the Transformer encoder architecture?\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: What are the roles of the feed-forward neural network and layer normalization in the Transformer encoder?\n",
      "Optimized query: What is the significance of feed-forward neural networks and layer normalization within the context of the Transformer encoder's functionality?\n",
      "============================================================\n",
      "\n",
      "  [Worker] Strategy: semantic (95%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: How are the connections and data flow structured between the sub-layers in the Transformer encoder?\n",
      "Optimized query: What is the overall structure and flow of information among the sub-layers within the Transformer encoder?\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: How does the self-attention mechanism work within the Transformer encoder?\n",
      "Optimized query: What is the underlying mechanism of self-attention in the context of the Transformer encoder, and how does it contribute to overall performance?\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Worker] Retrieved 4 docs, quality: 80%, attempt: 1/2\n",
      "Worker 2 complete: 4 docs, quality: 80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Worker] Retrieved 4 docs, quality: 80%, attempt: 1/2\n",
      "Worker 3 complete: 4 docs, quality: 80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Worker] Retrieved 4 docs, quality: 85%, attempt: 1/2\n",
      "Worker 0 complete: 4 docs, quality: 85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Worker] Retrieved 4 docs, quality: 80%, attempt: 1/2\n",
      "Worker 1 complete: 4 docs, quality: 80%\n",
      "\n",
      "============================================================\n",
      "MERGE RESULTS (SYNTHESIZER)\n",
      "Merging results from 4 workers\n",
      "Stage 1 (RRF): 7 unique docs -> 7 candidates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 (LLM Coverage): 7 candidates -> 6 selected\n",
      "Total unique docs: 7\n",
      "Multi-agent docs (in 2+ workers): 4\n",
      "Top-6 selected for generation\n",
      "Average quality: 81%\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\n",
      "Context size: 5456 chars\n",
      "Retrieval quality: 81%\n",
      "Generation attempt: 1/3\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION\n",
      "Generation attempt: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness: 83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 90%\n",
      "Decision: SUFFICIENT\n",
      "============================================================\n",
      "\n",
      "  Retrieval Quality: 81% | Groundedness: 83%\n",
      "\n",
      "================================================================================\n",
      "Comparison complete!\n"
     ]
    }
   ],
   "source": [
    "# Run 4-Tier Comparison\n",
    "test_query = \"Explain the complete forward pass through the Transformer encoder, including all sub-layers and their connections.\"\n",
    "\n",
    "graphs = {\n",
    "    \"Basic\": basic_rag_graph,\n",
    "    \"Intermediate\": intermediate_rag_graph,\n",
    "    \"Advanced\": advanced_rag_graph,\n",
    "    \"Multi-Agent\": multi_agent_rag_graph,\n",
    "}\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "for name, graph in graphs.items():\n",
    "    print(f\"\\nRunning {name} RAG...\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"user_question\": test_query,\n",
    "        \"baseline_query\": test_query,\n",
    "        \"messages\": [],\n",
    "        \"retrieved_docs\": [],\n",
    "        \"retrieval_attempts\": 0,\n",
    "        \"query_expansions\": [],\n",
    "        \"sub_agent_results\": [],\n",
    "    }\n",
    "    config = {\"configurable\": {\"thread_id\": f\"demo-{name.lower().replace('-', '_')}\"}}\n",
    "    \n",
    "    result = graph.invoke(initial_state, config=config)\n",
    "    results[name] = result\n",
    "    \n",
    "    # Show progress\n",
    "    quality = result.get(\"retrieval_quality_score\", 0) or 0\n",
    "    ground = result.get(\"groundedness_score\", 0) or 0\n",
    "    print(f\"  Retrieval Quality: {quality:.0%} | Groundedness: {ground:.0%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-8-results",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T08:01:59.492551Z",
     "iopub.status.busy": "2025-11-27T08:01:59.492551Z",
     "iopub.status.idle": "2025-11-27T08:01:59.502954Z",
     "shell.execute_reply": "2025-11-27T08:01:59.500944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "TIER            STRATEGY     DOCS   RETR Q     GROUND     ANSWER PREVIEW\n",
      "====================================================================================================\n",
      "Basic           semantic     4            0%         0%   The forward pass through the Transformer encoder involves se...\n",
      "Intermediate    semantic     4            0%         0%   The forward pass through the Transformer encoder involves se...\n",
      "Advanced        semantic     4           70%        95%   The forward pass through the Transformer encoder involves se...\n",
      "Multi-Agent     semantic     6           81%        83%   The complete forward pass through the Transformer encoder in...\n",
      "====================================================================================================\n",
      "\n",
      "Key Observations:\n",
      "- All tiers can answer the question, but with different retrieval approaches\n",
      "- Advanced tier may switch strategies or rewrite queries if initial retrieval is poor\n",
      "- Multi-Agent decomposes into sub-queries for comprehensive coverage\n"
     ]
    }
   ],
   "source": [
    "# Display Comparison Results\n",
    "print(\"=\"*100)\n",
    "print(f\"{'TIER':<15} {'STRATEGY':<12} {'DOCS':<6} {'RETR Q':<10} {'GROUND':<10} {'ANSWER PREVIEW'}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for name, result in results.items():\n",
    "    strategy = result.get(\"retrieval_strategy\", \"semantic\") or \"semantic\"\n",
    "    docs = len(result.get(\"unique_docs_list\", [])) if result.get(\"unique_docs_list\") else \"-\"\n",
    "    quality = result.get(\"retrieval_quality_score\", 0) or 0\n",
    "    ground = result.get(\"groundedness_score\", 0) or 0\n",
    "    answer = result.get(\"final_answer\", \"\")[:60] + \"...\" if result.get(\"final_answer\") else \"No answer\"\n",
    "    \n",
    "    print(f\"{name:<15} {strategy:<12} {str(docs):<6} {quality:>8.0%}   {ground:>8.0%}   {answer}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- All tiers can answer the question, but with different retrieval approaches\")\n",
    "print(\"- Advanced tier may switch strategies or rewrite queries if initial retrieval is poor\")\n",
    "print(\"- Multi-Agent decomposes into sub-queries for comprehensive coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9-selfcorrect",
   "metadata": {},
   "source": [
    "## Deep Dive: Self-Correction Loops\n",
    "\n",
    "The Advanced RAG tier implements two self-correction mechanisms:\n",
    "\n",
    "### 1. Retrieval Correction (max 2 attempts)\n",
    "When `retrieval_quality_score < 0.6`:\n",
    "- **Path A (off_topic/wrong_domain)**: Switch strategy immediately (semantic <-> keyword)\n",
    "- **Path B (other issues)**: Rewrite query using LLM-generated improvement suggestion\n",
    "\n",
    "### 2. Generation Retry (max 3 attempts)\n",
    "When answer fails quality evaluation:\n",
    "- Regenerate with combined feedback (quality issues + hallucination warnings)\n",
    "- Adaptive temperature: 0.3 (first retry), 0.7 (second retry)\n",
    "\n",
    "### Example Trace\n",
    "```\n",
    "Attempt 1: semantic search -> 45% quality (partial_coverage detected)\n",
    "  -> Rewrite: \"What are transformer encoders?\" -> \"Detailed architecture of transformer encoder layers\"\n",
    "Attempt 2: semantic search -> 72% quality (sufficient)\n",
    "  -> Generate answer\n",
    "  -> Evaluation: 85% groundedness, 80% quality -> SUFFICIENT\n",
    "```\n",
    "\n",
    "### Why Single Correction Cycle?\n",
    "Research (CRAG, Self-RAG) shows diminishing returns after the first correction. The architecture accepts imperfect retrieval rather than looping indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10-trace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T08:01:59.507949Z",
     "iopub.status.busy": "2025-11-27T08:01:59.507949Z",
     "iopub.status.idle": "2025-11-27T08:03:41.213280Z",
     "shell.execute_reply": "2025-11-27T08:03:41.211764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do attention mechanisms differ between NLP and vision applications?\n",
      "================================================================================\n",
      "\n",
      "Running Advanced RAG with potential self-correction...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY SELECTION\n",
      "Query: How do attention mechanisms differ between NLP and vision applications?\n",
      "Selected: HYBRID\n",
      "Confidence: 90%\n",
      "Reasoning: The user is seeking a comparison of attention mechanisms in two different domains (NLP and vision), which indicates a need for both conceptual understanding (how they differ) and specific terms (attention mechanisms in both contexts). This makes a hybrid approach optimal, as it allows for retrieving content that explains the differences while also ensuring that the specific terms related to attention mechanisms in both NLP and vision are accurately matched.\n",
      "Note: Query optimization will happen in query_expansion_node\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: hybrid\n",
      "Original query: How do attention mechanisms differ between NLP and vision applications?\n",
      "Optimized query: Attention mechanisms in NLP versus vision applications: key differences, implementations, and use cases\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPANSION DECISION\n",
      "Query: Attention mechanisms in NLP versus vision applications: key differences, implementations, and use cases\n",
      "LLM decision: EXPAND query\n",
      "Reasoning: The query addresses a complex topic with multiple facets (attention mechanisms in NLP and vision), which can be phrased in various ways. Expanding the query into variations can help capture different terminologies and perspectives, enhancing retrieval effectiveness.\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY EXPANDED\n",
      "Optimized query: Attention mechanisms in NLP versus vision applications: key differences, implementations, and use cases\n",
      "Expansions: ['Technical implementations and mechanisms of attention mechanisms in NLP compared to vision applications: what are the key differences?', 'Practical applications and use cases of attention mechanisms in NLP and vision: how do they differ?', 'Underlying concepts and principles of attention mechanisms in NLP versus vision applications: what are the key distinctions?']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL EXECUTION START\n",
      "Using 4 query expansion(s)\n",
      "Expansions generated from: retrieval_query\n",
      "Retrieval strategy: hybrid\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RRF MULTI-QUERY RETRIEVAL\n",
      "Query variants: 4\n",
      "Total retrievals: 56\n",
      "Unique docs after RRF: 32\n",
      "\n",
      "All 32 chunk IDs (RRF scores):\n",
      "  1. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_169 (0.0640)\n",
      "  2. Attention Is All You Need.pdf_chunk_17 (0.0567)\n",
      "  3. Attention Is All You Need.pdf_chunk_5 (0.0563)\n",
      "  4. Attention Is All You Need.pdf_chunk_49 (0.0487)\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_6 (0.0484)\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_35 (0.0462)\n",
      "  7. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_38 (0.0444)\n",
      "  8. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_14 (0.0318)\n",
      "  9. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (0.0305)\n",
      "  10. Attention Is All You Need.pdf_chunk_7 (0.0296)\n",
      "  11. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (0.0294)\n",
      "  12. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_79 (0.0292)\n",
      "  13. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_163 (0.0288)\n",
      "  14. Attention Is All You Need.pdf_chunk_14 (0.0276)\n",
      "  15. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_200 (0.0159)\n",
      "  16. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_85 (0.0159)\n",
      "  17. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_164 (0.0156)\n",
      "  18. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_48 (0.0154)\n",
      "  19. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_202 (0.0152)\n",
      "  20. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_176 (0.0149)\n",
      "  21. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_41 (0.0149)\n",
      "  22. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_44 (0.0147)\n",
      "  23. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_168 (0.0145)\n",
      "  24. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_197 (0.0143)\n",
      "  25. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_83 (0.0143)\n",
      "  26. Expanding Horizons in RAG - Exploring and Extending the Limits of RAPTOR.pdf_chunk_44 (0.0139)\n",
      "  27. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_157 (0.0137)\n",
      "  28. Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf_chunk_20 (0.0137)\n",
      "  29. Attention Is All You Need.pdf_chunk_34 (0.0137)\n",
      "  30. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_160 (0.0135)\n",
      "  31. Attention Is All You Need.pdf_chunk_39 (0.0135)\n",
      "  32. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_90 (0.0135)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TWO-STAGE RERANKING (After RRF)\n",
      "Input: 32 docs (from RRF top-40)\n",
      "\n",
      "Chunk IDs sent to reranking (top-40):\n",
      "  1. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_169\n",
      "  2. Attention Is All You Need.pdf_chunk_17\n",
      "  3. Attention Is All You Need.pdf_chunk_5\n",
      "  4. Attention Is All You Need.pdf_chunk_49\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_6\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_35\n",
      "  7. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_38\n",
      "  8. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_14\n",
      "  9. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5\n",
      "  10. Attention Is All You Need.pdf_chunk_7\n",
      "  ... and 22 more\n",
      "\n",
      "============================================================\n",
      "RERANKING QUERY SOURCE\n",
      "Using: active_query (semantic, human-readable)\n",
      "Query: How do attention mechanisms differ between NLP and vision applications?\n",
      "Note: Reranking uses semantic query, NOT algorithm-optimized retrieval_query\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output: 4 docs after two-stage reranking\n",
      "\n",
      "Final chunk IDs (after two-stage reranking):\n",
      "  1. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_41 (score: 85.0000)\n",
      "  2. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (score: 85.0000)\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (score: 85.0000)\n",
      "  4. Attention Is All You Need.pdf_chunk_17 (score: 80.0000)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ROUTER: AFTER RETRIEVAL\n",
      "Quality: 60% (threshold: >=60%)\n",
      "Attempts: 1/2\n",
      "Issues: missing_key_info, incomplete_context\n",
      "Decision: answer_generation (quality acceptable)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: How do attention mechanisms differ between NLP and vision applications?\n",
      "Context size: 4049 chars\n",
      "Retrieval quality: 60%\n",
      "Generation attempt: 1/3\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 1\n",
      "Retrieval quality: 60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refusal detection: ATTEMPTED - The assistant provided a detailed explanation of how attention mechanisms differ between NLP and vision applications, including specific implementations and challenges in both domains. While it acknowledged that the context does not cover all differences exhaustively, it still offered substantive information about the topic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 65% (insufficient)\n",
      "Issues: incomplete_synthesis, missing_details, partial_answer\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 2/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: How do attention mechanisms differ between NLP and vision applications?\n",
      "Context size: 4049 chars\n",
      "Retrieval quality: 60%\n",
      "Generation attempt: 2/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "QUALITY ISSUES:\n",
      "Problems: incomplete_synthesis, missing_details, partial_answer\n",
      "Fix: Provide more comprehensive synthesis of the relevant information; Add more depth and explanation where the context provides supporting information; Ensure all question parts are answered completely\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 2\n",
      "Retrieval quality: 60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refusal detection: ATTEMPTED - The assistant provided a detailed explanation of how attention mechanisms differ between NLP and vision applications, including specific examples and references to relevant papers. This indicates that the answer contains substantive information rather than a complete refusal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: END (max attempts reached)\n",
      "EXECUTION TRACE\n",
      "----------------------------------------\n",
      "Retrieval Attempts: 1\n",
      "Strategy Used: hybrid\n",
      "Final Retrieval Quality: 60%\n",
      "Issues Detected: missing_key_info, incomplete_context\n",
      "Improvement Suggestion: Rephrase to specifically ask for 'differences in attention mechanisms between NL...\n",
      "\n",
      "Generation Attempts: 2\n",
      "Groundedness: 100%\n",
      "Answer Sufficient: False\n",
      "\n",
      "================================================================================\n",
      "ANSWER (first 500 chars):\n",
      "----------------------------------------\n",
      "The attention mechanisms in natural language processing (NLP) and vision applications differ primarily in their application and scaling strategies. \n",
      "\n",
      "In NLP, Transformers utilize multi-head attention in various ways, including encoder-decoder attention, where queries come from the decoder and keys/values from the encoder, allowing the decoder to attend to all positions in the input sequence. Additionally, self-attention layers in both the encoder and decoder permit positions to attend to all pre...\n"
     ]
    }
   ],
   "source": [
    "# Self-Correction Example\n",
    "# This query might trigger self-correction due to domain ambiguity\n",
    "\n",
    "correction_query = \"How do attention mechanisms differ between NLP and vision applications?\"\n",
    "\n",
    "print(f\"Query: {correction_query}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nRunning Advanced RAG with potential self-correction...\\n\")\n",
    "\n",
    "initial_state = {\n",
    "    \"user_question\": correction_query,\n",
    "    \"baseline_query\": correction_query,\n",
    "    \"messages\": [],\n",
    "    \"retrieved_docs\": [],\n",
    "    \"retrieval_attempts\": 0,\n",
    "    \"query_expansions\": [],\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-selfcorrect\"}}\n",
    "\n",
    "result = advanced_rag_graph.invoke(initial_state, config=config)\n",
    "\n",
    "# Display self-correction trace\n",
    "print(\"EXECUTION TRACE\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Retrieval Attempts: {result.get('retrieval_attempts', 1)}\")\n",
    "print(f\"Strategy Used: {result.get('retrieval_strategy', 'semantic')}\")\n",
    "\n",
    "if result.get('strategy_changed'):\n",
    "    print(f\"Strategy Changed: Yes\")\n",
    "    print(f\"  Reason: {result.get('strategy_switch_reason', 'N/A')}\")\n",
    "\n",
    "quality = result.get('retrieval_quality_score', 0) or 0\n",
    "print(f\"Final Retrieval Quality: {quality:.0%}\")\n",
    "\n",
    "if result.get('retrieval_quality_issues'):\n",
    "    print(f\"Issues Detected: {', '.join(result['retrieval_quality_issues'])}\")\n",
    "\n",
    "if result.get('retrieval_improvement_suggestion'):\n",
    "    print(f\"Improvement Suggestion: {result['retrieval_improvement_suggestion'][:80]}...\")\n",
    "\n",
    "print(f\"\\nGeneration Attempts: {result.get('generation_attempts', 1)}\")\n",
    "print(f\"Groundedness: {(result.get('groundedness_score', 0) or 0):.0%}\")\n",
    "print(f\"Answer Sufficient: {result.get('is_answer_sufficient', True)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANSWER (first 500 chars):\")\n",
    "print(\"-\"*40)\n",
    "print(result.get('final_answer', 'No answer')[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11-metrics",
   "metadata": {},
   "source": [
    "## Evaluation Metrics Summary\n",
    "\n",
    "Golden dataset evaluation (10 hard questions, budget model tier):\n",
    "\n",
    "| Tier | F1@6 | Groundedness | Factual Accuracy |\n",
    "|------|------|--------------|------------------|\n",
    "| Basic | 29.0% | 99.0% | 92.1% |\n",
    "| Intermediate | 27.0% | 97.5% | 88.2% |\n",
    "| Advanced | 30.1% | 95.6% | 77.5% |\n",
    "| Multi-Agent | 38.8% | 97.6% | 84.0% |\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "**Retrieval Quality (F1@6)**\n",
    "- Multi-Agent shows +30% improvement over Basic on complex queries\n",
    "- Query decomposition helps find relevant documents across multiple aspects\n",
    "\n",
    "**Groundedness** (% of claims supported by context)\n",
    "- All tiers maintain >95% groundedness\n",
    "- NLI-based detection catches unsupported claims\n",
    "\n",
    "**Architecture Value Proposition**\n",
    "- Budget tier (GPT-4o-mini) demonstrates that architecture matters\n",
    "- Self-correction loops improve robustness, not just metrics\n",
    "- Higher tiers provide better answers on hard questions\n",
    "\n",
    "### When to Use Each Tier\n",
    "- **Basic**: Simple factual lookups, low latency requirements\n",
    "- **Intermediate**: Production workloads with quality requirements\n",
    "- **Advanced**: Complex domains where query understanding matters\n",
    "- **Multi-Agent**: Research synthesis, multi-faceted questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-12-testresults",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T08:03:41.216662Z",
     "iopub.status.busy": "2025-11-27T08:03:41.215627Z",
     "iopub.status.idle": "2025-11-27T08:03:41.249947Z",
     "shell.execute_reply": "2025-11-27T08:03:41.248435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATEST EVALUATION RESULTS\n",
      "============================================================\n",
      "Dataset: hard\n",
      "Model Tier: budget\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display Latest Test Results\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load latest evaluation results\n",
    "eval_dir = Path(\"evaluation\")\n",
    "latest_file = eval_dir / \"architecture_comparison_results_hard_latest.json\"\n",
    "\n",
    "if latest_file.exists():\n",
    "    with open(latest_file) as f:\n",
    "        eval_data = json.load(f)\n",
    "    \n",
    "    print(\"LATEST EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Dataset: {eval_data.get('config', {}).get('dataset', 'hard')}\")\n",
    "    print(f\"Model Tier: {eval_data.get('config', {}).get('model_tier', 'budget')}\")\n",
    "    print()\n",
    "    \n",
    "    for tier, metrics in eval_data.get('summary', {}).items():\n",
    "        if isinstance(metrics, dict):\n",
    "            f1 = metrics.get('f1_at_k', 0) * 100\n",
    "            ground = metrics.get('groundedness', 0) * 100\n",
    "            fact = metrics.get('factual_accuracy', 0) * 100\n",
    "            print(f\"{tier:<15} F1@6: {f1:>5.1f}%  Ground: {ground:>5.1f}%  Factual: {fact:>5.1f}%\")\n",
    "else:\n",
    "    print(\"No evaluation results found. Run test_architecture_comparison.py to generate.\")\n",
    "    print(\"\\nExpected metrics (from golden dataset):\")\n",
    "    print(\"  Basic:        F1@6: 29.0%  Ground: 99.0%\")\n",
    "    print(\"  Intermediate: F1@6: 27.0%  Ground: 97.5%\")\n",
    "    print(\"  Advanced:     F1@6: 30.1%  Ground: 95.6%\")\n",
    "    print(\"  Multi-Agent:  F1@6: 38.8%  Ground: 97.6%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13-conclusion",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Architecture > Model Size** - The graph structure provides value independent of model quality. Budget tier demonstrates the RAG intelligence; higher tiers add polish.\n",
    "\n",
    "2. **Distributed Decision-Making** - No central orchestrator. The StateGraph itself is the agent, with routing functions encoding planning logic.\n",
    "\n",
    "3. **Quality-Driven Flow** - Every routing point evaluates results and decides next action. Poor retrieval triggers correction; poor generation triggers retry.\n",
    "\n",
    "4. **Multi-Agent for Complexity** - Query decomposition with parallel workers significantly improves F1@6 on complex, multi-faceted questions.\n",
    "\n",
    "### Source Code\n",
    "\n",
    "```\n",
    "src/advanced_agentic_rag_langgraph/\n",
    "    core/              # State, retriever, model config\n",
    "    orchestration/     # Main graph, nodes, routing\n",
    "    retrieval/         # Strategy selection, reranking\n",
    "    evaluation/        # Quality assessment, NLI detection\n",
    "    variants/          # Basic, Intermediate, Advanced, Multi-Agent\n",
    "```\n",
    "\n",
    "### How to Extend\n",
    "\n",
    "1. **Add new retrieval strategies** - Implement in `retrieval/strategy_selection.py`\n",
    "2. **Custom quality metrics** - Extend `evaluation/retrieval_quality.py`\n",
    "3. **Different document types** - Modify `core/setup_retriever.py`\n",
    "4. **Production deployment** - Add LangSmith tracing, async execution\n",
    "\n",
    "### Related Resources\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [RAG Evaluation Guide](https://docs.langchain.com/langsmith/evaluate-rag-tutorial)\n",
    "- [Build a Custom RAG Agent](https://docs.langchain.com/oss/python/langgraph/agentic-rag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
