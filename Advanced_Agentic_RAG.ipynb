{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-1-intro",
   "metadata": {},
   "source": [
    "# Advanced Agentic RAG with LangGraph\n",
    "\n",
    "**A portfolio project showcasing intelligent, adaptive retrieval pipelines**\n",
    "\n",
    "This system demonstrates production-grade RAG architecture patterns:\n",
    "\n",
    "- **Dynamic strategy selection** - Semantic, keyword, or hybrid retrieval based on query analysis\n",
    "- **Quality-driven self-correction** - Automatic query rewrites when retrieval quality is insufficient\n",
    "- **Multi-stage reranking** - CrossEncoder (top-10) + LLM-as-judge (top-4) for precision\n",
    "- **HHEM-based hallucination detection** - Claim decomposition with per-chunk HHEM-2.1-Open verification\n",
    "- **Multi-agent parallel retrieval** - Query decomposition with parallel workers for complex questions\n",
    "\n",
    "**Architecture**: 7-node StateGraph with distributed intelligence (no central orchestrator)  \n",
    "**Framework**: LangChain 1.0 & LangGraph 1.0  \n",
    "**Pattern**: Dynamic Planning and Execution Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:55:37.058491Z",
     "iopub.status.busy": "2025-11-27T07:55:37.058491Z",
     "iopub.status.idle": "2025-11-27T07:56:34.893409Z",
     "shell.execute_reply": "2025-11-27T07:56:34.891880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG variants loaded:\n",
      "  - basic_rag_graph: Simplest RAG (semantic search only)\n",
      "  - intermediate_rag_graph: Query expansion + hybrid + reranking\n",
      "  - advanced_rag_graph: Full agentic RAG with self-correction\n",
      "  - multi_agent_rag_graph: Parallel retrieval workers\n"
     ]
    }
   ],
   "source": [
    "# Setup & Imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# All RAG graph variants\n",
    "from advanced_agentic_rag_langgraph.variants import (\n",
    "    basic_rag_graph,\n",
    "    intermediate_rag_graph,\n",
    "    advanced_rag_graph,\n",
    "    multi_agent_rag_graph,\n",
    ")\n",
    "\n",
    "print(\"RAG variants loaded:\")\n",
    "print(\"  - basic_rag_graph: Simplest RAG (semantic search only)\")\n",
    "print(\"  - intermediate_rag_graph: Query expansion + hybrid + reranking\")\n",
    "print(\"  - advanced_rag_graph: Full agentic RAG with self-correction\")\n",
    "print(\"  - multi_agent_rag_graph: Parallel retrieval workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3-diagram",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:56:34.897447Z",
     "iopub.status.busy": "2025-11-27T07:56:34.897447Z",
     "iopub.status.idle": "2025-11-27T07:56:36.525070Z",
     "shell.execute_reply": "2025-11-27T07:56:36.524050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Architecture Diagram - LangGraph Mermaid Visualization\n",
    "from IPython.display import Image\n",
    "\n",
    "# Render the Advanced RAG graph structure\n",
    "Image(advanced_rag_graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4-routing",
   "metadata": {},
   "source": [
    "## Routing Logic (What the Diagram Doesn't Show)\n",
    "\n",
    "The graph visualization shows nodes and edges, but the **conditional routing logic** is where the \"intelligence\" lives:\n",
    "\n",
    "### `route_after_retrieval` - Quality-Based Branching\n",
    "```python\n",
    "if quality >= 0.6:\n",
    "    return \"answer_generation\"  # Good enough - proceed\n",
    "\n",
    "if attempts >= 2:\n",
    "    return \"answer_generation\"  # Max attempts - proceed anyway\n",
    "\n",
    "if (\"off_topic\" in issues or \"wrong_domain\" in issues) and (attempts == 1):\n",
    "    return \"query_expansion\"    # Early strategy switch\n",
    "else:\n",
    "    return \"rewrite_and_refine\" # Semantic rewrite\n",
    "```\n",
    "\n",
    "### `route_after_evaluation` - Answer Quality Gate\n",
    "```python\n",
    "if is_refusal:\n",
    "    return END  # LLM refused - terminal state\n",
    "\n",
    "if is_answer_sufficient:\n",
    "    return END\n",
    "\n",
    "if generation_attempts < 3:\n",
    "    return \"answer_generation\"  # Retry with feedback\n",
    "else:\n",
    "    return END  # Max attempts reached\n",
    "```\n",
    "\n",
    "### Key Design Principles\n",
    "- **Fix generation with generation** - Don't re-retrieve for generation problems\n",
    "- **Single correction cycle** - Research shows diminishing returns after first retry\n",
    "- **Adaptive thresholds** - Lower quality bar (50%) when retrieval is poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5-retriever",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:56:36.529086Z",
     "iopub.status.busy": "2025-11-27T07:56:36.529086Z",
     "iopub.status.idle": "2025-11-27T07:57:38.702131Z",
     "shell.execute_reply": "2025-11-27T07:57:38.700599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING ALL PDFS FROM docs/\n",
      "============================================================\n",
      "\n",
      "Found 10 PDF file(s):\n",
      "  1. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf (3.6 MB)\n",
      "  2. Attention Is All You Need.pdf (2.1 MB)\n",
      "  3. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf (0.7 MB)\n",
      "  4. Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf (30.1 MB)\n",
      "  5. Denoising Diffusion Probabilistic Models.pdf (9.8 MB)\n",
      "  6. Expanding Horizons in RAG - Exploring and Extending the Limits of RAPTOR.pdf (0.6 MB)\n",
      "  7. Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf (40.9 MB)\n",
      "  8. Improved Training of Wasserstein GANs.pdf (5.9 MB)\n",
      "  9. Learning Transferable Visual Models From Natural Language Supervision.pdf (6.5 MB)\n",
      "  10. U-Net - Convolutional Networks for Biomedical Image Segmentation.pdf (1.6 MB)\n",
      "\n",
      "============================================================\n",
      "STEP 1: Loading full documents (no chunking)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Loading 10 PDFs as full documents (no chunking)...\n",
      "Loading full document: AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf\n",
      "  Pages: 22, Characters: 67,154\n",
      "Loading full document: Attention Is All You Need.pdf\n",
      "  Pages: 15, Characters: 39,511\n",
      "Loading full document: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf\n",
      "  Pages: 16, Characters: 64,131\n",
      "Loading full document: Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf\n",
      "  Pages: 42, Characters: 97,294\n",
      "Loading full document: Denoising Diffusion Probabilistic Models.pdf\n",
      "  Pages: 25, Characters: 54,041\n",
      "Loading full document: Expanding Horizons in RAG - Exploring and Extending the Limits of RAPTOR.pdf\n",
      "  Pages: 11, Characters: 37,149\n",
      "Loading full document: Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf\n",
      "  Pages: 27, Characters: 56,402\n",
      "Loading full document: Improved Training of Wasserstein GANs.pdf\n",
      "  Pages: 20, Characters: 41,584\n",
      "Loading full document: Learning Transferable Visual Models From Natural Language Supervision.pdf\n",
      "  Pages: 48, Characters: 224,303\n",
      "Loading full document: U-Net - Convolutional Networks for Biomedical Image Segmentation.pdf\n",
      "  Pages: 8, Characters: 19,623\n",
      "\n",
      "Loaded 10 full documents, 701,192 total characters\n",
      "\n",
      "============================================================\n",
      "STEP 2: Profiling documents with LLM\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "DOCUMENT PROFILING\n",
      "============================================================\n",
      "Profiling 10 documents...\n",
      "\n",
      "Document 1 (doc_0):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, transformers, deep_learning\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 2 (doc_1):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, deep_learning, nlp\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 3 (doc_2):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: natural_language_processing, transformers, deep_learning\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 4 (doc_3):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, generative_models, diffusion_models\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 5 (doc_4):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, deep_learning, computer_vision\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 6 (doc_5):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: nlp, retrieval_augmented_generation, machine_learning\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 7 (doc_6):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, machine_learning, generative_models\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 8 (doc_7):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: machine_learning, deep_learning, generative_adversarial_networks\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 9 (doc_8):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.90\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, natural_language_processing, machine_learning\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "Document 10 (doc_9):\n",
      "  Type: conference_paper\n",
      "  Technical Density: 0.80\n",
      "  Reading Level: advanced\n",
      "  Domain: computer_vision, deep_learning, biomedical_image_segmentation\n",
      "  Best Strategy: hybrid\n",
      "\n",
      "============================================================\n",
      "CORPUS STATISTICS\n",
      "============================================================\n",
      "Total Documents: 10\n",
      "Average Technical Density: 0.86\n",
      "\n",
      "Document Types:\n",
      "  - conference_paper: 10 (100.0%)\n",
      "\n",
      "Domain Distribution:\n",
      "  - computer_vision: 5\n",
      "  - transformers: 2\n",
      "  - deep_learning: 6\n",
      "  - machine_learning: 7\n",
      "  - nlp: 2\n",
      "  - natural_language_processing: 2\n",
      "  - generative_models: 2\n",
      "  - diffusion_models: 1\n",
      "  - retrieval_augmented_generation: 1\n",
      "  - generative_adversarial_networks: 1\n",
      "  - biomedical_image_segmentation: 1\n",
      "\n",
      "Percentage with Code: 50.0%\n",
      "Percentage with Math: 70.0%\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "STEP 3: Chunking documents\n",
      "============================================================\n",
      "\n",
      "Created 924 chunks from 10 documents\n",
      "\n",
      "============================================================\n",
      "CORPUS STATISTICS\n",
      "============================================================\n",
      "Total documents: 10\n",
      "Total chunks: 924\n",
      "Avg technical density: 0.86\n",
      "Document types: {'conference_paper': 10}\n",
      "Has code: 50%\n",
      "Has math: 70%\n",
      "============================================================\n",
      "\n",
      "\n",
      "Retriever initialized with 10 research papers (924 chunks)\n",
      "Papers include: Transformers, BERT, ViT, DDPM, CLIP, U-Net, WGAN-GP, Consistency Models\n"
     ]
    }
   ],
   "source": [
    "# Initialize Retriever (one-time setup)\n",
    "# This loads 10 research papers and creates the vector store\n",
    "from advanced_agentic_rag_langgraph.core import setup_retriever\n",
    "\n",
    "k_final=4\n",
    "retriever = setup_retriever(k_final=k_final)\n",
    "print(\"\\nRetriever initialized with 10 research papers (924 chunks)\")\n",
    "print(\"Papers include: Transformers, BERT, ViT, DDPM, CLIP, U-Net, WGAN-GP, Consistency Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6-tiers",
   "metadata": {},
   "source": [
    "## 4-Tier Architecture Comparison\n",
    "\n",
    "Each tier adds capabilities while using the **same budget model tier** (GPT-4o-mini) to isolate architectural improvements from model quality:\n",
    "\n",
    "| Tier | Features | Key Additions |\n",
    "|------|----------|---------------|\n",
    "| **Basic** | 1 | Semantic search only, direct LLM generation |\n",
    "| **Intermediate** | 5 | + Query expansion, hybrid retrieval, CrossEncoder reranking, RRF fusion |\n",
    "| **Advanced** | 17 | + Strategy selection, two-stage reranking, HHEM detection, quality gates, self-correction loops |\n",
    "| **Multi-Agent** | 20 | + Query decomposition, parallel retrieval workers, cross-agent LLM relevance scoring |\n",
    "\n",
    "### Feature Progression\n",
    "- **Basic**: Pure semantic similarity - works well for simple, direct questions\n",
    "- **Intermediate**: Query variations improve recall, reranking improves precision\n",
    "- **Advanced**: Adapts strategy based on query type, retries on poor results\n",
    "- **Multi-Agent**: Decomposes complex questions, retrieves in parallel, merges results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7-comparison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T07:57:38.705124Z",
     "iopub.status.busy": "2025-11-27T07:57:38.705124Z",
     "iopub.status.idle": "2025-11-27T08:01:59.488551Z",
     "shell.execute_reply": "2025-11-27T08:01:59.487529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Ground Truth Chunks: 4 (from attention paper)\n",
      "================================================================================\n",
      "\n",
      "Running Basic RAG...\n",
      "\n",
      "============================================================\n",
      "BASIC RETRIEVAL\n",
      "Strategy: semantic only (vector similarity)\n",
      "Top-K: 4 chunks (no reranking)\n",
      "Retrieved: 4 documents\n",
      "\n",
      "All 4 chunk IDs (rank order):\n",
      "  1. Attention Is All You Need.pdf_chunk_6\n",
      "  2. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31\n",
      "  3. Attention Is All You Need.pdf_chunk_10\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_69\n",
      "\n",
      "Expected chunks: ['Attention Is All You Need.pdf_chunk_28', 'Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "Found: [] | Missing: ['Attention Is All You Need.pdf_chunk_28', 'Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Answer length: 1592 chars\n",
      "Context docs: 4\n",
      "============================================================\n",
      "\n",
      "  F1@4: 0%\n",
      "\n",
      "Running Intermediate RAG...\n",
      "\n",
      "============================================================\n",
      "QUERY EXPANSION\n",
      "Original: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Generated 4 variations\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID RETRIEVAL WITH RRF FUSION\n",
      "Strategy: hybrid (always)\n",
      "Query variants: 4\n",
      "Total retrievals: 53\n",
      "Unique docs after RRF: 29\n",
      "\n",
      "All 29 chunk IDs (RRF scores):\n",
      "  1. Attention Is All You Need.pdf_chunk_6 (0.0648)\n",
      "  2. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_3 (0.0635)\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (0.0619)\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_69 (0.0604)\n",
      "  5. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31 (0.0474)\n",
      "  6. Attention Is All You Need.pdf_chunk_5 (0.0459)\n",
      "  7. Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf_chunk_54 (0.0458)\n",
      "  8. Attention Is All You Need.pdf_chunk_28 (0.0435)\n",
      "  9. Attention Is All You Need.pdf_chunk_10 (0.0310)\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_71 (0.0292)\n",
      "  11. Attention Is All You Need.pdf_chunk_1 (0.0286)\n",
      "  12. Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf_chunk_26 (0.0280)\n",
      "  13. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_12 (0.0152)\n",
      "  14. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (0.0152)\n",
      "  15. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_12 (0.0149)\n",
      "  16. Attention Is All You Need.pdf_chunk_2 (0.0147)\n",
      "  17. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_20 (0.0145)\n",
      "  18. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_70 (0.0145)\n",
      "  19. Attention Is All You Need.pdf_chunk_8 (0.0143)\n",
      "  20. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_9 (0.0143)\n",
      "  21. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_58 (0.0141)\n",
      "  22. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_64 (0.0141)\n",
      "  23. Consistency Models - faster alternative to traditional diffusion models; directly mapping noise to data.pdf_chunk_110 (0.0139)\n",
      "  24. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_159 (0.0139)\n",
      "  25. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_57 (0.0139)\n",
      "  26. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_73 (0.0137)\n",
      "  27. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_68 (0.0137)\n",
      "  28. Denoising Diffusion Probabilistic Models.pdf_chunk_61 (0.0135)\n",
      "  29. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_111 (0.0135)\n",
      "\n",
      "Expected chunks: ['Attention Is All You Need.pdf_chunk_28', 'Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "Found: ['Attention Is All You Need.pdf_chunk_28'] | Missing: ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "CROSSENCODER RERANKING\n",
      "Input: 29 documents\n",
      "\n",
      "Chunk IDs sent to reranking (top-15):\n",
      "  1. Attention Is All You Need.pdf_chunk_6\n",
      "  2. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_3\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_69\n",
      "  5. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31\n",
      "  6. Attention Is All You Need.pdf_chunk_5\n",
      "  7. Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf_chunk_54\n",
      "  8. Attention Is All You Need.pdf_chunk_28\n",
      "  9. Attention Is All You Need.pdf_chunk_10\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_71\n",
      "  ... and 5 more\n",
      "\n",
      "Expected chunks in reranking input:\n",
      "Found: ['Attention Is All You Need.pdf_chunk_28'] | Missing: ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "\n",
      "Output: 4 documents after CrossEncoder reranking\n",
      "\n",
      "Final chunk IDs (after CrossEncoder reranking):\n",
      "  1. Attention Is All You Need.pdf_chunk_1 (score: -0.6854)\n",
      "  2. Attention Is All You Need.pdf_chunk_28 (score: -2.3592)\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_12 (score: -2.4223)\n",
      "  4. Attention Is All You Need.pdf_chunk_6 (score: -2.7427)\n",
      "\n",
      "Expected chunks in final results:\n",
      "Found: ['Attention Is All You Need.pdf_chunk_28'] | Missing: ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Answer length: 2413 chars\n",
      "Context docs: 4\n",
      "============================================================\n",
      "\n",
      "  F1@4: 25%\n",
      "\n",
      "Running Advanced RAG...\n",
      "\n",
      "============================================================\n",
      "STRATEGY SELECTION\n",
      "Query: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Selected: SEMANTIC\n",
      "Confidence: 90%\n",
      "Reasoning: The user is seeking a detailed explanation of the training procedure for the Transformer model, which indicates a desire for conceptual understanding and comprehensive information. This aligns with the semantic search strengths in finding content that explains processes and methodologies. The query includes multi-token terms like 'training procedure', 'optimization', 'regularization', and 'learning rate schedule', which are better preserved and understood through semantic search rather than keyword search. Given the technical nature of the corpus, which is focused on deep learning and transformers, semantic search will effectively retrieve relevant documents that provide the necessary explanations and insights.\n",
      "Note: Query optimization will happen in query_expansion_node\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Optimized query: Explain the comprehensive training process for the Transformer model, focusing on key aspects such as optimization techniques, regularization methods, and strategies for adjusting the learning rate throughout the training.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EXPANSION DECISION\n",
      "Query: Explain the comprehensive training process for the Transformer model, focusing on key aspects such as optimization techniques, regularization methods, and strategies for adjusting the learning rate throughout the training.\n",
      "LLM decision: EXPAND query\n",
      "Reasoning: The query is complex and covers multiple aspects of the Transformer model's training process. Expanding it into variations can help capture different terminologies and phrasing that users might employ when searching for information on optimization techniques, regularization methods, and learning rate adjustments. This will enhance retrieval effectiveness by addressing potential synonyms and related concepts.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY EXPANDED\n",
      "Optimized query: Explain the comprehensive training process for the Transformer model, focusing on key aspects such as optimization techniques, regularization methods, and strategies for adjusting the learning rate throughout the training.\n",
      "Expansions: ['What are the technical implementation details and optimization techniques involved in the training process of the Transformer model, including regularization methods and learning rate adjustments?', 'In what practical scenarios is the training process of the Transformer model applied, particularly regarding optimization techniques, regularization methods, and learning rate strategies?', 'What are the underlying principles of the comprehensive training process for the Transformer model, focusing on key aspects like optimization techniques, regularization methods, and learning rate adjustment strategies?']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL EXECUTION START\n",
      "Using 4 query expansion(s)\n",
      "Expansions generated from: retrieval_query\n",
      "Retrieval strategy: semantic\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RRF MULTI-QUERY RETRIEVAL\n",
      "Query variants: 4\n",
      "Total retrievals: 60\n",
      "Unique docs after RRF: 22\n",
      "\n",
      "All 22 chunk IDs (RRF scores):\n",
      "  1. Attention Is All You Need.pdf_chunk_6 (0.0648)\n",
      "  2. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_3 (0.0638)\n",
      "  3. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31 (0.0623)\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_69 (0.0598)\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (0.0592)\n",
      "  6. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_20 (0.0586)\n",
      "  7. Attention Is All You Need.pdf_chunk_1 (0.0560)\n",
      "  8. Attention Is All You Need.pdf_chunk_5 (0.0477)\n",
      "  9. Attention Is All You Need.pdf_chunk_10 (0.0436)\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_71 (0.0429)\n",
      "  11. Attention Is All You Need.pdf_chunk_2 (0.0423)\n",
      "  12. Attention Is All You Need.pdf_chunk_17 (0.0423)\n",
      "  13. Attention Is All You Need.pdf_chunk_32 (0.0308)\n",
      "  14. Attention Is All You Need.pdf_chunk_39 (0.0294)\n",
      "  15. Hierarchical Text-Conditional Image Generation with CLIP Latents.pdf_chunk_54 (0.0288)\n",
      "  16. Attention Is All You Need.pdf_chunk_28 (0.0285)\n",
      "  17. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_30 (0.0276)\n",
      "  18. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_32 (0.0276)\n",
      "  19. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_42 (0.0272)\n",
      "  20. Attention Is All You Need.pdf_chunk_8 (0.0149)\n",
      "  21. Denoising Diffusion Probabilistic Models.pdf_chunk_59 (0.0143)\n",
      "  22. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_31 (0.0135)\n",
      "\n",
      "Expected chunks: ['Attention Is All You Need.pdf_chunk_28', 'Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "Found: ['Attention Is All You Need.pdf_chunk_28'] | Missing: ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TWO-STAGE RERANKING (After RRF)\n",
      "Input: 22 docs (from RRF top-40)\n",
      "\n",
      "Chunk IDs sent to reranking (top-40):\n",
      "  1. Attention Is All You Need.pdf_chunk_6\n",
      "  2. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_3\n",
      "  3. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_69\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5\n",
      "  6. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_20\n",
      "  7. Attention Is All You Need.pdf_chunk_1\n",
      "  8. Attention Is All You Need.pdf_chunk_5\n",
      "  9. Attention Is All You Need.pdf_chunk_10\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_71\n",
      "  ... and 12 more\n",
      "\n",
      "Expected chunks in reranking input:\n",
      "Found: ['Attention Is All You Need.pdf_chunk_28'] | Missing: ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "\n",
      "============================================================\n",
      "RERANKING QUERY SOURCE\n",
      "Using: active_query (semantic, human-readable)\n",
      "Query: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Note: Reranking uses semantic query, NOT algorithm-optimized retrieval_query\n",
      "============================================================\n",
      "\n",
      "\n",
      "Output: 4 docs after two-stage reranking\n",
      "\n",
      "Final chunk IDs (after two-stage reranking):\n",
      "  1. Attention Is All You Need.pdf_chunk_28 (score: 90.0000)\n",
      "  2. Attention Is All You Need.pdf_chunk_1 (score: 40.0000)\n",
      "  3. Attention Is All You Need.pdf_chunk_6 (score: 40.0000)\n",
      "  4. Attention Is All You Need.pdf_chunk_32 (score: 40.0000)\n",
      "\n",
      "Expected chunks in final results:\n",
      "Found: ['Attention Is All You Need.pdf_chunk_28'] | Missing: ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30', 'Attention Is All You Need.pdf_chunk_31']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL METRICS (Golden Dataset Evaluation)\n",
      "============================================================\n",
      "Recall@4:    25.00%\n",
      "Precision@4: 25.00%\n",
      "F1@4:        25.00%\n",
      "Hit Rate:    100.00%\n",
      "MRR:         1.0000\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ROUTER: AFTER RETRIEVAL\n",
      "Quality: 70% (threshold: >=60%)\n",
      "Attempts: 1/2\n",
      "Issues: partial_coverage, missing_key_info\n",
      "Decision: answer_generation (quality acceptable)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Context size: 3725 chars\n",
      "Retrieval quality: 70%\n",
      "Generation attempt: 1/3\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 1\n",
      "Retrieval quality: 70%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about the training procedure for the Transformer, including details on the training environment, optimizer, learning rate schedule, and mentions regularization. Although it acknowledges a gap regarding the specific types of regularization, it still contains useful information, thus it is not a full refusal.\n",
      "Groundedness: 92%\n",
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 2/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Context size: 3725 chars\n",
      "Retrieval quality: 70%\n",
      "Generation attempt: 2/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "QUALITY ISSUES:\n",
      "Problems: partial_answer, missing_details\n",
      "Fix: Ensure all question parts are answered completely; Add more depth and explanation where the context provides supporting information\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 2\n",
      "Retrieval quality: 70%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about the training procedure for the Transformer, including details on the training environment, optimizer, and learning rate schedule. Although it acknowledges a gap regarding the specific types of regularization used, it still contains useful information, which means it is not a full refusal.\n",
      "Groundedness: 92%\n",
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 3/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Context size: 3725 chars\n",
      "Retrieval quality: 70%\n",
      "Generation attempt: 3/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "QUALITY ISSUES:\n",
      "Problems: partial_answer, missing_details\n",
      "Fix: Ensure all question parts are answered completely; Add more depth and explanation where the context provides supporting information\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 3\n",
      "Retrieval quality: 70%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about the training procedure for the Transformer, including details on the training environment, optimizer, and learning rate schedule. Although it acknowledges a gap regarding the specific types of regularization used, it still contains useful information, which means it is not a full refusal.\n",
      "Groundedness: 92%\n",
      "Quality: 65% (insufficient)\n",
      "Issues: missing_details, partial_answer\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: END (max attempts reached)\n",
      "  F1@4: 25%\n",
      "\n",
      "Running Multi-Agent RAG...\n",
      "\n",
      "============================================================\n",
      "COMPLEXITY CLASSIFICATION\n",
      "Query: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Classification: COMPLEX\n",
      "Reasoning: The query involves multiple distinct aspects: the training procedure, optimization, regularization, and learning rate schedule, which would benefit from focused sub-queries for clarity and depth.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY DECOMPOSITION (ORCHESTRATOR)\n",
      "Original: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Sub-queries (4):\n",
      "  1. What is the complete training procedure for the Transformer?\n",
      "  2. What optimization techniques are used in the training of the Transformer?\n",
      "  3. What regularization methods are applied during the training of the Transformer?\n",
      "  4. What learning rate schedule is implemented in the training of the Transformer?\n",
      "Reasoning: Four aspects (training procedure, optimization, regularization, learning rate schedule) = 4 sub-queries.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ASSIGN WORKERS (Send API)\n",
      "Spawning 4 parallel retrieval workers\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 0\n",
      "Sub-query: What is the complete training procedure for the Transformer?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 1\n",
      "Sub-query: What optimization techniques are used in the training of the Transformer?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 2\n",
      "Sub-query: What regularization methods are applied during the training of the Transformer?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL WORKER 3\n",
      "Sub-query: What learning rate schedule is implemented in the training of the Transformer?\n",
      "============================================================\n",
      "  [Worker] Strategy: semantic (90%)\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: What regularization methods are applied during the training of the Transformer?\n",
      "Optimized query: What are the various regularization techniques utilized in the training process of the Transformer model?\n",
      "============================================================\n",
      "\n",
      "  [Worker] Strategy: semantic (90%)\n",
      "  [Worker] Strategy: semantic (90%)\n",
      "  [Worker] Strategy: semantic (95%)\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: What learning rate schedule is implemented in the training of the Transformer?\n",
      "Optimized query: What are the strategies and principles behind the learning rate schedule used in training the Transformer model?\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: What optimization techniques are used in the training of the Transformer?\n",
      "Optimized query: What are the various techniques and strategies employed to optimize the training process of the Transformer model?\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: What is the complete training procedure for the Transformer?\n",
      "Optimized query: What are the essential steps and methodologies involved in the complete training process of the Transformer model?\n",
      "============================================================\n",
      "\n",
      "  [Worker] Retrieved 4 docs, quality: 60%, attempt: 1/2\n",
      "Worker 2 complete: 4 docs, quality: 60%\n",
      "  [Worker] Retrieved 4 docs, quality: 80%, attempt: 1/2\n",
      "Worker 3 complete: 4 docs, quality: 80%\n",
      "  [Worker] Retrieved 4 docs, quality: 50%, attempt: 1/2\n",
      "  [Worker] Rewritten: What optimization techniques are used in the train... -> What optimization techniques or training methods a...\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: semantic\n",
      "Original query: What optimization techniques or training methods are used in the training of the Transformer?\n",
      "Optimized query: What are the various optimization techniques and training methods utilized in the development and enhancement of the Transformer model?\n",
      "============================================================\n",
      "\n",
      "  [Worker] Retrieved 4 docs, quality: 60%, attempt: 1/2\n",
      "Worker 0 complete: 4 docs, quality: 60%\n",
      "  [Worker] Retrieved 4 docs, quality: 60%, attempt: 2/2\n",
      "Worker 1 complete: 4 docs, quality: 60%\n",
      "\n",
      "============================================================\n",
      "MERGE RESULTS (SYNTHESIZER)\n",
      "Merging results from 4 workers\n",
      "Deduplication: 16 total -> 12 unique -> 12 candidates\n",
      "Expected chunks: Found ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30'] | Missing ['Attention Is All You Need.pdf_chunk_28', 'Attention Is All You Need.pdf_chunk_31']\n",
      "\n",
      "============================================================\n",
      "LLM RELEVANCE SCORING (Multi-Agent Merge)\n",
      "Original question: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Candidates: 12\n",
      "\n",
      "Chunk IDs before scoring:\n",
      "  1. Attention Is All You Need.pdf_chunk_1\n",
      "  2. Attention Is All You Need.pdf_chunk_6\n",
      "  3. Attention Is All You Need.pdf_chunk_30\n",
      "  4. Attention Is All You Need.pdf_chunk_35\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_69\n",
      "  7. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31\n",
      "  8. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_32\n",
      "  9. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_3\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5\n",
      "  11. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_295\n",
      "  12. Attention Is All You Need.pdf_chunk_29\n",
      "\n",
      "LLM Scores (all 12 candidates):\n",
      "  1. Attention Is All You Need.pdf_chunk_1 (score: 20.0)\n",
      "  2. Attention Is All You Need.pdf_chunk_6 (score: 20.0)\n",
      "  3. Attention Is All You Need.pdf_chunk_30 (score: 75.0)\n",
      "  4. Attention Is All You Need.pdf_chunk_35 (score: 60.0)\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (score: 40.0)\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_69 (score: 60.0)\n",
      "  7. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31 (score: 70.0)\n",
      "  8. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_32 (score: 50.0)\n",
      "  9. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_3 (score: 40.0)\n",
      "  10. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (score: 30.0)\n",
      "  11. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_295 (score: 80.0)\n",
      "  12. Attention Is All You Need.pdf_chunk_29 (score: 90.0)\n",
      "\n",
      "Final selection (top-4):\n",
      "  1. Attention Is All You Need.pdf_chunk_29 (score: 90.0)\n",
      "  2. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_295 (score: 80.0)\n",
      "  3. Attention Is All You Need.pdf_chunk_30 (score: 75.0)\n",
      "  4. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_31 (score: 70.0)\n",
      "============================================================\n",
      "\n",
      "LLM Scoring: 12 candidates -> 4 selected\n",
      "\n",
      "Expected chunks in final selection:\n",
      "Found: ['Attention Is All You Need.pdf_chunk_29', 'Attention Is All You Need.pdf_chunk_30'] | Missing: ['Attention Is All You Need.pdf_chunk_28', 'Attention Is All You Need.pdf_chunk_31']\n",
      "Total unique docs: 12\n",
      "Multi-agent docs (in 2+ workers): 3\n",
      "Top-4 selected for generation\n",
      "Average quality: 79%\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Context size: 4128 chars\n",
      "Retrieval quality: 79%\n",
      "Generation attempt: 1/3\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 1\n",
      "Retrieval quality: 79%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about the optimization, regularization, and some aspects of the learning rate schedule for the Transformer model. Although it acknowledges a gap in the details of the learning rate schedule, it still includes relevant facts about the Adam optimizer, dropout regularization, and label smoothing, which indicates that it is a partial answer rather than a full refusal.\n",
      "Groundedness: 69%\n",
      "Quality: 75% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 2/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Context size: 4128 chars\n",
      "Retrieval quality: 79%\n",
      "Generation attempt: 2/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "HALLUCINATION DETECTED (69% grounded):\n",
      "Unsupported claims: The hyperparameter \\( \\beta_1 \\) for the Adam optimizer is 0.9., The hyperparameter \\( \\beta_2 \\) for the Adam optimizer is 0.999., The hyperparameter \\( \\epsilon \\) for the Adam optimizer is \\( 10^{-8} \\) for ResNet., The hyperparameter \\( \\epsilon \\) for the Adam optimizer is \\( 10^{-6} \\) for the Vision Transformer.\n",
      "Fix: ONLY state facts explicitly in retrieved context. If information is missing, acknowledge the limitation rather than adding unsupported details.\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 2\n",
      "Retrieval quality: 79%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about the training procedure for the Transformer model, including details on optimization (using the Adam optimizer), regularization (dropout), label smoothing, and mentions of the learning rate schedule. Although it acknowledges gaps in specific hyperparameters and the exact learning rate schedule, it still contains useful information, which qualifies it as a partial answer rather than a full refusal.\n",
      "Groundedness: 82%\n",
      "Quality: 70% (insufficient)\n",
      "Issues: incomplete_synthesis, missing_details, partial_answer\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 3/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\n",
      "Context size: 4128 chars\n",
      "Retrieval quality: 79%\n",
      "Generation attempt: 3/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "QUALITY ISSUES:\n",
      "Problems: incomplete_synthesis, missing_details, partial_answer\n",
      "Fix: Provide more comprehensive synthesis of the relevant information; Add more depth and explanation where the context provides supporting information; Ensure all question parts are answered completely\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 3\n",
      "Retrieval quality: 79%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about the optimization method (Adam optimizer with specific hyperparameters), regularization techniques (dropout), and label smoothing. Although it acknowledges a lack of details regarding the learning rate schedule, it still contains useful information, which qualifies it as a partial answer rather than a full refusal.\n",
      "Groundedness: 73%\n",
      "Quality: 75% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "  F1@4: 50%\n",
      "\n",
      "================================================================================\n",
      "Comparison complete!\n"
     ]
    }
   ],
   "source": [
    "# Run 4-Tier Comparison\n",
    "# Using a query from golden dataset so we can calculate F1@4\n",
    "\n",
    "from advanced_agentic_rag_langgraph.evaluation.retrieval_metrics import calculate_retrieval_metrics\n",
    "from advanced_agentic_rag_langgraph.validation import HHEMHallucinationDetector\n",
    "\n",
    "# Import modules to inject shared retriever\n",
    "import advanced_agentic_rag_langgraph.variants.basic_rag_graph as basic_module\n",
    "import advanced_agentic_rag_langgraph.variants.intermediate_rag_graph as intermediate_module\n",
    "import advanced_agentic_rag_langgraph.orchestration.nodes as advanced_module\n",
    "import advanced_agentic_rag_langgraph.variants.multi_agent_rag_graph as multi_agent_module\n",
    "\n",
    "# Inject pre-built retriever into all variants\n",
    "basic_module.adaptive_retriever = retriever\n",
    "intermediate_module.adaptive_retriever = retriever\n",
    "advanced_module.adaptive_retriever = retriever\n",
    "multi_agent_module.adaptive_retriever = retriever\n",
    "\n",
    "# Query from golden_set_standard.json (transformer_training_procedure)\n",
    "test_query = \"Describe the complete training procedure for the Transformer, including optimization, regularization, and learning rate schedule.\"\n",
    "ground_truth_doc_ids = [\n",
    "      \"Attention Is All You Need.pdf_chunk_28\",\n",
    "      \"Attention Is All You Need.pdf_chunk_29\",\n",
    "      \"Attention Is All You Need.pdf_chunk_30\",\n",
    "      \"Attention Is All You Need.pdf_chunk_31\"\n",
    "]\n",
    "\n",
    "graphs = {\n",
    "    \"Basic\": basic_rag_graph,\n",
    "    \"Intermediate\": intermediate_rag_graph,\n",
    "    \"Advanced\": advanced_rag_graph,\n",
    "    \"Multi-Agent\": multi_agent_rag_graph,\n",
    "}\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Ground Truth Chunks: {len(ground_truth_doc_ids)} (from attention paper)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "for name, graph in graphs.items():\n",
    "    print(f\"\\nRunning {name} RAG...\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"user_question\": test_query,\n",
    "        \"baseline_query\": test_query,\n",
    "        \"messages\": [],\n",
    "        \"retrieved_docs\": [],\n",
    "        \"retrieval_attempts\": 0,\n",
    "        \"query_expansions\": [],\n",
    "        \"sub_agent_results\": [],\n",
    "        \"ground_truth_doc_ids\": ground_truth_doc_ids,\n",
    "    }\n",
    "    config = {\"configurable\": {\"thread_id\": f\"demo-{name.lower().replace('-', '_')}\"}}\n",
    "    \n",
    "    result = graph.invoke(initial_state, config=config)\n",
    "    results[name] = result\n",
    "    \n",
    "    # Calculate F1@4 for progress display\n",
    "    docs = result.get(\"unique_docs_list\", [])\n",
    "    if docs:\n",
    "        metrics = calculate_retrieval_metrics(docs, ground_truth_doc_ids, k_final)\n",
    "        f1 = metrics[\"f1_at_k\"]\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    print(f\"  F1@{k_final}: {f1:.0%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8-results",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T08:01:59.492551Z",
     "iopub.status.busy": "2025-11-27T08:01:59.492551Z",
     "iopub.status.idle": "2025-11-27T08:01:59.502954Z",
     "shell.execute_reply": "2025-11-27T08:01:59.500944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "4-TIER ARCHITECTURE COMPARISON RESULTS\n",
      "================================================================================\n",
      "\n",
      "[BASIC]\n",
      "Strategy: semantic  |  Docs: 4  |  F1@4: 0%  |  Groundedness: 65%\n",
      "--------------------------------------------------------------------------------\n",
      "The training procedure for the Transformer involves several key components:\n",
      "\n",
      "1. **Model Architecture**: The Transformer model consists of an encoder and decoder, each composed of a stack of identical layers. For the encoder, there are 6 layers, each with a multi-head self-attention mechanism followed by a position-wise fully connected feed-forward network.\n",
      "\n",
      "2. **Optimizer**: The Adam optimizer is used for training, which is known for its efficiency in handling large datasets and models. It incorporates mechanisms like momentum and adaptive learning rates.\n",
      "\n",
      "3. **Regularization**: Decoupled weight decay regularization is applied to all weights in the model, except for gains and biases. This helps prevent overfitting by penalizing large weights during training.\n",
      "\n",
      "4. **Learning Rate Schedule**: A cosine learning rate schedule is employed, where the learning rate decreases following a cosine curve over the training period. This schedule allows for a gradual reduction in the learning rate, which can help improve convergence and training stability.\n",
      "\n",
      "5. **Hyperparameter Tuning**: Initial hyperparameters are set using a combination of grid searches, random search, and manual tuning, particularly on a baseline ResNet-50 model trained for 1 epoch. These hyperparameters are then adapted heuristically for larger models.\n",
      "\n",
      "6. **Training Epochs**: All models, including the Transformer, are trained for a total of 32 epochs.\n",
      "\n",
      "This comprehensive procedure allows the Transformer to effectively learn from the data while managing issues like overfitting and ensuring efficient convergence.\n",
      "================================================================================\n",
      "\n",
      "[INTERMEDIATE]\n",
      "Strategy: semantic  |  Docs: 4  |  F1@4: 25%  |  Groundedness: 79%\n",
      "--------------------------------------------------------------------------------\n",
      "The training procedure for the Transformer involves several key components, including optimization, regularization, and a learning rate schedule.\n",
      "\n",
      "### Optimization\n",
      "The Transformer model utilizes the Adam optimizer with the following parameters:\n",
      "- **1** = 0.9\n",
      "- **2** = 0.98\n",
      "- **** = 10^-9\n",
      "\n",
      "### Learning Rate Schedule\n",
      "The learning rate is varied throughout the training process according to the formula:\n",
      "\n",
      "\\[ \\text{lrate} = d^{-0.5} \\cdot \\min(\\text{step\\_num}^{-0.5}, \\text{step\\_num} \\cdot \\text{warmup\\_steps}^{-1.5}) \\]\n",
      "\n",
      "In this schedule:\n",
      "- The learning rate is increased linearly for the first `warmup_steps` (set at 4000) training steps.\n",
      "- After the warmup period, the learning rate is decreased proportionally to the inverse square root of the step number.\n",
      "\n",
      "### Regularization\n",
      "Three types of regularization techniques are employed during training to enhance model generalization:\n",
      "1. **Constant Latent Vector Size**: The Transformer maintains a constant latent vector size (D) across all layers, which helps in stabilizing training.\n",
      "2. **Patch Embeddings**: Input patches are flattened and mapped to D dimensions using a trainable linear projection, which adds an additional layer of representation.\n",
      "3. **Position Embeddings**: Learnable 1D position embeddings are added to the patch embeddings to retain positional information of the input data. Advanced 2D-aware position embeddings were tested but did not yield significant performance improvements.\n",
      "\n",
      "### Training Steps\n",
      "- The base models were trained for a total of **100,000 steps**, taking approximately **12 hours** on eight NVIDIA P100 GPUs, with each training step taking about **0.4 seconds**.\n",
      "- The big models were trained for **300,000 steps** over **3.5 days**, with each training step taking about **1.0 second**.\n",
      "\n",
      "### Model Representation\n",
      "During training, a learnable embedding (similar to BERT's [class] token) is prepended to the sequence of embedded patches. The output of this embedding at the end of the Transformer encoder serves as the image representation, with a classification head attached for both pre-training and fine-tuning stages.\n",
      "\n",
      "### Summary\n",
      "Overall, the training procedure for the Transformer is structured to maximize efficiency and performance through the use of advanced optimization techniques, a strategic learning rate schedule, and regularization methods that enhance the model's capacity to generalize across tasks.\n",
      "================================================================================\n",
      "\n",
      "[ADVANCED]\n",
      "Strategy: semantic  |  Docs: 4  |  F1@4: 25%  |  Groundedness: 92%\n",
      "--------------------------------------------------------------------------------\n",
      "The training procedure for the Transformer model includes the following components:\n",
      "\n",
      "1. **Training Environment**: The models were trained on a machine equipped with 8 NVIDIA P100 GPUs. The base models had a training step duration of approximately 0.4 seconds and were trained for a total of 100,000 steps, which took about 12 hours. In contrast, the larger models had a step duration of 1.0 seconds and were trained for 300,000 steps, resulting in a training time of around 3.5 days.\n",
      "\n",
      "2. **Optimizer**: The Adam optimizer was utilized with parameters 1 = 0.9, 2 = 0.98, and  = 109. The learning rate was adjusted throughout the training process according to the formula:\n",
      "   \\[\n",
      "   lrate = d^{-0.5} \\cdot \\min(step\\_num^{-0.5}, step\\_num \\cdot warmup\\_steps^{-1.5})\n",
      "   \\]\n",
      "   This indicates that the learning rate increased linearly for the first 4,000 steps (referred to as warmup_steps) and subsequently decreased in proportion to the inverse square root of the step number.\n",
      "\n",
      "3. **Regularization**: The training employed three types of regularization. However, the specific types of regularization used are not detailed in the retrieved context.\n",
      "\n",
      "The context provides a comprehensive overview of the training procedure, including the training environment, optimization strategy, and learning rate schedule. However, it does not specify the exact types of regularization used during training.\n",
      "================================================================================\n",
      "\n",
      "[MULTI-AGENT]\n",
      "Strategy: semantic  |  Docs: 4  |  F1@4: 50%  |  Groundedness: 73%\n",
      "--------------------------------------------------------------------------------\n",
      "The training procedure for the Transformer model includes the following components:\n",
      "\n",
      "1. **Optimization**: The Transformer model employs the Adam optimizer. The specific hyperparameters for the Adam optimizer are:\n",
      "   - \\( \\beta_1 = 0.9 \\)\n",
      "   - \\( \\beta_2 = 0.999 \\)\n",
      "   - \\( \\epsilon = 10^{-8} \\) (though this value may vary depending on the model, it is commonly used in practice).\n",
      "\n",
      "2. **Regularization**: Dropout is utilized as a regularization technique. It is applied to the output of each sub-layer before it is added to the sub-layer input and normalized. Additionally, dropout is applied to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, the dropout rate is set at \\( P_{drop} = 0.1 \\).\n",
      "\n",
      "3. **Learning Rate Schedule**: The context does not provide specific details about the learning rate schedule used for the Transformer model. It mentions that other models, such as ResNets, utilize a cosine schedule for decaying the learning rate, but it does not confirm whether a similar approach is applied to the Transformer.\n",
      "\n",
      "4. **Label Smoothing**: During training, label smoothing is employed with a value of \\( \\epsilon_{ls} = 0.1 \\). This technique is noted to improve the model's accuracy and BLEU score, although it may negatively affect perplexity by making the model less certain.\n",
      "\n",
      "In summary, the context provides detailed information on optimization (including specific hyperparameters), regularization through dropout, and label smoothing. However, it lacks complete details on the learning rate schedule used for the Transformer model.\n",
      "================================================================================\n",
      "\n",
      "Key Observations:\n",
      "- F1@4 measures retrieval quality against known ground truth chunks\n",
      "- Groundedness measures % of answer claims supported by retrieved context (via HHEM)\n",
      "- Multi-Agent shows best F1@4 due to query decomposition finding more relevant chunks\n"
     ]
    }
   ],
   "source": [
    "# Display Comparison Results\n",
    "# Calculate F1@4 and Groundedness independently (not from graph state)\n",
    "\n",
    "hhem_detector = HHEMHallucinationDetector()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"4-TIER ARCHITECTURE COMPARISON RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, result in results.items():\n",
    "    strategy = result.get(\"retrieval_strategy\", \"semantic\") or \"semantic\"\n",
    "    docs = result.get(\"unique_docs_list\", [])\n",
    "    answer = result.get(\"final_answer\", \"\")\n",
    "\n",
    "    # Calculate F1@4 using ground truth\n",
    "    if docs:\n",
    "        metrics = calculate_retrieval_metrics(docs, ground_truth_doc_ids, k_final)\n",
    "        f1_at_k = metrics[\"f1_at_k\"]\n",
    "    else:\n",
    "        f1_at_k = 0.0\n",
    "\n",
    "    # Calculate groundedness using HHEM\n",
    "    if docs and answer:\n",
    "        chunks = [doc.page_content for doc in docs[:k_final]]\n",
    "        groundedness_result = hhem_detector.verify_groundedness(answer, chunks)\n",
    "        groundedness = groundedness_result[\"groundedness_score\"]\n",
    "    else:\n",
    "        groundedness = 0.0\n",
    "\n",
    "    print(f\"\\n[{name.upper()}]\")\n",
    "    print(f\"Strategy: {strategy}  |  Docs: {len(docs)}  |  F1@4: {f1_at_k:.0%}  |  Groundedness: {groundedness:.0%}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(answer if answer else \"No answer\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- F1@4 measures retrieval quality against known ground truth chunks\")\n",
    "print(\"- Groundedness measures % of answer claims supported by retrieved context (via HHEM)\")\n",
    "print(\"- Multi-Agent shows best F1@4 due to query decomposition finding more relevant chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9-selfcorrect",
   "metadata": {},
   "source": [
    "## Deep Dive: Self-Correction Loops\n",
    "\n",
    "The Advanced RAG tier implements two self-correction mechanisms:\n",
    "\n",
    "### 1. Retrieval Correction (max 2 attempts)\n",
    "When `retrieval_quality_score < 0.6`:\n",
    "- **Path A (off_topic/wrong_domain)**: Switch strategy immediately (semantic <-> keyword)\n",
    "- **Path B (other issues)**: Rewrite query using LLM-generated improvement suggestion\n",
    "\n",
    "### 2. Generation Retry (max 3 attempts)\n",
    "When answer fails quality evaluation:\n",
    "- Regenerate with combined feedback (quality issues + hallucination warnings)\n",
    "- Low temperature: 0.3\n",
    "\n",
    "### Example Trace\n",
    "```\n",
    "Attempt 1: semantic search -> 45% quality (partial_coverage detected)\n",
    "  -> Rewrite: \"What are transformer encoders?\" -> \"Detailed architecture of transformer encoder layers\"\n",
    "Attempt 2: semantic search -> 72% quality (sufficient)\n",
    "  -> Generate answer\n",
    "  -> Evaluation: 85% groundedness, 80% quality -> SUFFICIENT\n",
    "```\n",
    "\n",
    "### Why Single Correction Cycle?\n",
    "Research (CRAG, Self-RAG) shows diminishing returns after the first correction. The architecture accepts imperfect retrieval rather than looping indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-trace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T08:01:59.507949Z",
     "iopub.status.busy": "2025-11-27T08:01:59.507949Z",
     "iopub.status.idle": "2025-11-27T08:03:41.213280Z",
     "shell.execute_reply": "2025-11-27T08:03:41.211764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do attention mechanisms differ between NLP and vision applications?\n",
      "================================================================================\n",
      "\n",
      "Running Advanced RAG with potential self-correction...\n",
      "\n",
      "\n",
      "============================================================\n",
      "STRATEGY SELECTION\n",
      "Query: How do attention mechanisms differ between NLP and vision applications?\n",
      "Selected: HYBRID\n",
      "Confidence: 90%\n",
      "Reasoning: The user is seeking a comparison of attention mechanisms in two different domains (NLP and vision), which indicates a need for both conceptual understanding (how they differ) and specific terms (attention mechanisms in both contexts). This makes a hybrid approach optimal, as it allows for retrieving content that explains the differences while also ensuring that the specific terms related to attention mechanisms in both NLP and vision are accurately matched.\n",
      "Note: Query optimization will happen in query_expansion_node\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: hybrid\n",
      "Original query: How do attention mechanisms differ between NLP and vision applications?\n",
      "Optimized query: attention mechanisms in NLP versus vision applications: differences in functionality and implementation\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EXPANSION DECISION\n",
      "Query: attention mechanisms in NLP versus vision applications: differences in functionality and implementation\n",
      "LLM decision: EXPAND query\n",
      "Reasoning: The query addresses a complex topic comparing attention mechanisms in NLP and vision applications, which can benefit from variations in phrasing and terminology. Users may use different terms or focus on specific aspects of functionality and implementation, making expansion useful for capturing a broader range of relevant documents.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY EXPANDED\n",
      "Optimized query: attention mechanisms in NLP versus vision applications: differences in functionality and implementation\n",
      "Expansions: ['What are the technical implementation details and mechanisms of attention mechanisms in NLP compared to vision applications?', 'What are some practical applications or use cases that highlight the differences in functionality of attention mechanisms between NLP and vision fields?', 'What are the fundamental concepts and principles that differentiate attention mechanisms in NLP from those used in vision applications?']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL EXECUTION START\n",
      "Using 4 query expansion(s)\n",
      "Expansions generated from: retrieval_query\n",
      "Retrieval strategy: hybrid\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RRF MULTI-QUERY RETRIEVAL\n",
      "Query variants: 4\n",
      "Total retrievals: 53\n",
      "Unique docs after RRF: 26\n",
      "\n",
      "All 26 chunk IDs (RRF scores):\n",
      "  1. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_169 (0.0624)\n",
      "  2. Attention Is All You Need.pdf_chunk_49 (0.0617)\n",
      "  3. Attention Is All You Need.pdf_chunk_5 (0.0563)\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_6 (0.0484)\n",
      "  5. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_14 (0.0458)\n",
      "  6. Attention Is All You Need.pdf_chunk_17 (0.0447)\n",
      "  7. Attention Is All You Need.pdf_chunk_14 (0.0415)\n",
      "  8. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_35 (0.0315)\n",
      "  9. Attention Is All You Need.pdf_chunk_7 (0.0308)\n",
      "  10. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_163 (0.0306)\n",
      "  11. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_41 (0.0306)\n",
      "  12. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (0.0306)\n",
      "  13. Attention Is All You Need.pdf_chunk_44 (0.0301)\n",
      "  14. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_38 (0.0299)\n",
      "  15. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_128 (0.0297)\n",
      "  16. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_79 (0.0288)\n",
      "  17. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_170 (0.0284)\n",
      "  18. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_200 (0.0154)\n",
      "  19. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_48 (0.0152)\n",
      "  20. Attention Is All You Need.pdf_chunk_43 (0.0152)\n",
      "  21. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_164 (0.0152)\n",
      "  22. Attention Is All You Need.pdf_chunk_0 (0.0147)\n",
      "  23. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_42 (0.0139)\n",
      "  24. Attention Is All You Need.pdf_chunk_39 (0.0137)\n",
      "  25. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_160 (0.0137)\n",
      "  26. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_157 (0.0135)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TWO-STAGE RERANKING (After RRF)\n",
      "Input: 26 docs (from RRF top-40)\n",
      "\n",
      "Chunk IDs sent to reranking (top-40):\n",
      "  1. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_169\n",
      "  2. Attention Is All You Need.pdf_chunk_49\n",
      "  3. Attention Is All You Need.pdf_chunk_5\n",
      "  4. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_6\n",
      "  5. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_14\n",
      "  6. Attention Is All You Need.pdf_chunk_17\n",
      "  7. Attention Is All You Need.pdf_chunk_14\n",
      "  8. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_35\n",
      "  9. Attention Is All You Need.pdf_chunk_7\n",
      "  10. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_163\n",
      "  ... and 16 more\n",
      "\n",
      "============================================================\n",
      "RERANKING QUERY SOURCE\n",
      "Using: active_query (semantic, human-readable)\n",
      "Query: How do attention mechanisms differ between NLP and vision applications?\n",
      "Note: Reranking uses semantic query, NOT algorithm-optimized retrieval_query\n",
      "============================================================\n",
      "\n",
      "\n",
      "Output: 4 docs after two-stage reranking\n",
      "\n",
      "Final chunk IDs (after two-stage reranking):\n",
      "  1. Attention Is All You Need.pdf_chunk_17 (score: 90.0000)\n",
      "  2. Attention Is All You Need.pdf_chunk_7 (score: 85.0000)\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (score: 80.0000)\n",
      "  4. Attention Is All You Need.pdf_chunk_5 (score: 80.0000)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ROUTER: AFTER RETRIEVAL\n",
      "Quality: 50% (threshold: >=60%)\n",
      "Attempts: 1/2\n",
      "Issues: missing_key_info\n",
      "Decision: rewrite_and_refine (semantic rewrite)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY REWRITING\n",
      "Original query: How do attention mechanisms differ between NLP and vision applications?\n",
      "Retrieval quality: 50%\n",
      "Improvement suggestion: Rephrase to specifically ask for 'differences in attention mechanisms between NLP and vision applications'.\n",
      "Issues detected: missing_key_info\n",
      "============================================================\n",
      "\n",
      "Rewritten query: What are the differences in attention mechanisms specifically between NLP and vision applications?\n",
      "Note: Query expansions cleared - will regenerate for rewritten query\n",
      "\n",
      "State clearing (semantic rewrite takes precedence):\n",
      "  query_expansions: [] (will regenerate)\n",
      "  retrieval_query: None (cleared to prevent stale optimization)\n",
      "  active_query: What are the differences in attention mechanisms specifically between NLP and vision applications? (semantic rewrite)\n",
      "\n",
      "\n",
      "============================================================\n",
      "STRATEGY-SPECIFIC QUERY OPTIMIZATION\n",
      "Strategy: hybrid\n",
      "Original query: What are the differences in attention mechanisms specifically between NLP and vision applications?\n",
      "Optimized query: What are the specific differences in attention mechanisms between NLP (Natural Language Processing) and vision applications, including their theoretical foundations and practical implications?\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "EXPANSION DECISION\n",
      "Query: What are the specific differences in attention mechanisms between NLP (Natural Language Processing) and vision applications, including their theoretical foundations and practical implications?\n",
      "LLM decision: EXPAND query\n",
      "Reasoning: The query is complex and involves multiple concepts (attention mechanisms, NLP, vision applications, theoretical foundations, practical implications) that could benefit from variations in phrasing and terminology. Users may approach the topic with different perspectives or terminology, making expansion useful for capturing a broader range of relevant information.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY EXPANDED\n",
      "Optimized query: What are the specific differences in attention mechanisms between NLP (Natural Language Processing) and vision applications, including their theoretical foundations and practical implications?\n",
      "Expansions: ['What are the technical implementations and mechanisms of attention mechanisms in NLP (Natural Language Processing) compared to vision applications?', 'What are some practical applications and use cases that illustrate the differences in attention mechanisms between NLP (Natural Language Processing) and vision applications?', 'What are the theoretical foundations and underlying concepts that differentiate attention mechanisms in NLP (Natural Language Processing) from those used in vision applications?']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL EXECUTION START\n",
      "Using 4 query expansion(s)\n",
      "Expansions generated from: retrieval_query\n",
      "Retrieval strategy: hybrid\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RRF MULTI-QUERY RETRIEVAL\n",
      "Query variants: 4\n",
      "Total retrievals: 55\n",
      "Unique docs after RRF: 29\n",
      "\n",
      "All 29 chunk IDs (RRF scores):\n",
      "  1. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_169 (0.0651)\n",
      "  2. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_14 (0.0631)\n",
      "  3. Attention Is All You Need.pdf_chunk_5 (0.0558)\n",
      "  4. Attention Is All You Need.pdf_chunk_14 (0.0550)\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (0.0472)\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_6 (0.0459)\n",
      "  7. Attention Is All You Need.pdf_chunk_43 (0.0453)\n",
      "  8. Attention Is All You Need.pdf_chunk_17 (0.0419)\n",
      "  9. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_163 (0.0318)\n",
      "  10. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_164 (0.0301)\n",
      "  11. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (0.0297)\n",
      "  12. Attention Is All You Need.pdf_chunk_44 (0.0297)\n",
      "  13. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_35 (0.0296)\n",
      "  14. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_42 (0.0282)\n",
      "  15. Attention Is All You Need.pdf_chunk_49 (0.0156)\n",
      "  16. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_57 (0.0156)\n",
      "  17. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_170 (0.0154)\n",
      "  18. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_128 (0.0154)\n",
      "  19. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_41 (0.0152)\n",
      "  20. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_165 (0.0149)\n",
      "  21. Attention Is All You Need.pdf_chunk_7 (0.0149)\n",
      "  22. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_200 (0.0147)\n",
      "  23. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_48 (0.0147)\n",
      "  24. BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf_chunk_62 (0.0147)\n",
      "  25. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_79 (0.0145)\n",
      "  26. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_162 (0.0143)\n",
      "  27. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_157 (0.0137)\n",
      "  28. Expanding Horizons in RAG - Exploring and Extending the Limits of RAPTOR.pdf_chunk_39 (0.0137)\n",
      "  29. Attention Is All You Need.pdf_chunk_39 (0.0135)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TWO-STAGE RERANKING (After RRF)\n",
      "Input: 29 docs (from RRF top-40)\n",
      "\n",
      "Chunk IDs sent to reranking (top-40):\n",
      "  1. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_169\n",
      "  2. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_14\n",
      "  3. Attention Is All You Need.pdf_chunk_5\n",
      "  4. Attention Is All You Need.pdf_chunk_14\n",
      "  5. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1\n",
      "  6. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_6\n",
      "  7. Attention Is All You Need.pdf_chunk_43\n",
      "  8. Attention Is All You Need.pdf_chunk_17\n",
      "  9. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_163\n",
      "  10. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_164\n",
      "  ... and 19 more\n",
      "\n",
      "============================================================\n",
      "RERANKING QUERY SOURCE\n",
      "Using: active_query (semantic, human-readable)\n",
      "Query: What are the differences in attention mechanisms specifically between NLP and vision applications?\n",
      "Note: Reranking uses semantic query, NOT algorithm-optimized retrieval_query\n",
      "============================================================\n",
      "\n",
      "\n",
      "Output: 4 docs after two-stage reranking\n",
      "\n",
      "Final chunk IDs (after two-stage reranking):\n",
      "  1. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_5 (score: 90.0000)\n",
      "  2. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_41 (score: 85.0000)\n",
      "  3. AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf_chunk_1 (score: 80.0000)\n",
      "  4. Learning Transferable Visual Models From Natural Language Supervision.pdf_chunk_170 (score: 75.0000)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ROUTER: AFTER RETRIEVAL\n",
      "Quality: 50% (threshold: >=60%)\n",
      "Attempts: 2/2\n",
      "Issues: missing_key_info, partial_coverage\n",
      "Decision: answer_generation (max attempts reached)\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: How do attention mechanisms differ between NLP and vision applications?\n",
      "Context size: 4095 chars\n",
      "Retrieval quality: 50%\n",
      "Generation attempt: 1/3\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 1\n",
      "Retrieval quality: 50%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about how attention mechanisms differ between NLP and vision applications, specifically discussing the use of self-attention in NLP and the adaptation of this mechanism in Vision Transformers. It acknowledges limitations in the context but still offers relevant details, which indicates it is a partial answer rather than a full refusal.\n",
      "Groundedness: 80%\n",
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 2/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: How do attention mechanisms differ between NLP and vision applications?\n",
      "Context size: 4095 chars\n",
      "Retrieval quality: 50%\n",
      "Generation attempt: 2/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "QUALITY ISSUES:\n",
      "Problems: partial_answer, missing_details\n",
      "Fix: Ensure all question parts are answered completely; Add more depth and explanation where the context provides supporting information\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 2\n",
      "Retrieval quality: 50%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about how attention mechanisms are implemented in NLP and vision applications, specifically discussing the use of self-attention in Transformers for NLP and the adaptation of this mechanism in Vision Transformers (ViT) for images. Although it acknowledges that the context does not provide detailed comparisons or implications, it still offers relevant facts and explanations about the differences in attention mechanisms.\n",
      "Groundedness: 85%\n",
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: answer_generation (attempt 3/3)\n",
      "\n",
      "============================================================\n",
      "ANSWER GENERATION\n",
      "Question: How do attention mechanisms differ between NLP and vision applications?\n",
      "Context size: 4095 chars\n",
      "Retrieval quality: 50%\n",
      "Generation attempt: 3/3\n",
      "============================================================\n",
      "\n",
      "RETRY MODE:\n",
      "Feedback:\n",
      "QUALITY ISSUES:\n",
      "Problems: partial_answer, missing_details\n",
      "Fix: Ensure all question parts are answered completely; Add more depth and explanation where the context provides supporting information\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANSWER EVALUATION (Refusal + Groundedness + Quality)\n",
      "Generation attempt: 3\n",
      "Retrieval quality: 50%\n",
      "Refusal detection: ATTEMPTED - The answer provides substantive information about how attention mechanisms differ between NLP and vision applications, specifically discussing the use of self-attention in NLP and the adaptation of this mechanism in Vision Transformers. It acknowledges limitations in the context but still offers relevant details about the implementations and challenges faced in both domains.\n",
      "Groundedness: 69%\n",
      "Quality: 65% (insufficient)\n",
      "Issues: partial_answer, missing_details\n",
      "Combined decision: RETRY\n",
      "============================================================\n",
      "\n",
      "\n",
      "Routing: END (max attempts reached)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXECUTION TRACE\n",
      "----------------------------------------\n",
      "Retrieval Attempts: 2\n",
      "Strategy Used: hybrid\n",
      "Final Retrieval Quality: 50%\n",
      "Issues Detected: missing_key_info, partial_coverage\n",
      "Improvement Suggestion: Add 'differences in attention mechanisms between NLP and vision' to the query for more targeted results.\n",
      "\n",
      "Generation Attempts: 3\n",
      "Groundedness: 69%\n",
      "Answer Sufficient: False\n",
      "\n",
      "================================================================================\n",
      "ANSWER:\n",
      "----------------------------------------\n",
      "Attention mechanisms in NLP and vision applications differ primarily in their implementation and scalability due to the nature of the data they process.\n",
      "\n",
      "In NLP, Transformers utilize self-attention to allow each word in a sequence to attend to every other word. This mechanism effectively captures complex relationships within the text and has become the state of the art in various NLP tasks. Models like BERT and GPT are examples of this approach, where they are pre-trained on large text corpora and then fine-tuned for specific tasks (as noted in the document \"AN IMAGE IS WORTH 16X16 WORDS - TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\").\n",
      "\n",
      "In contrast, applying self-attention directly to images poses significant challenges. The naive approach would require each pixel to attend to every other pixel, resulting in a quadratic computational cost that does not scale well for realistic image sizes. To address this, the Vision Transformer (ViT) interprets an image as a sequence of patches rather than individual pixels. This adaptation allows the use of a standard Transformer encoder, similar to those used in NLP, while managing computational efficiency. The ViT has shown to match or exceed state-of-the-art performance in image classification tasks while requiring substantially fewer computational resources compared to traditional convolutional networks (as highlighted in the same document).\n",
      "\n",
      "The context does not provide detailed comparisons of specific attention mechanisms or their operational differences beyond the general application in NLP versus vision. It also does not discuss the implications of these differences on model performance or architecture design in depth.\n",
      "\n",
      "In summary, the context explains that NLP employs self-attention on sequences of words, while vision applications like ViT adapt this by using patches of images to manage computational efficiency. However, it does not cover specific operational differences or implications of these mechanisms in detail.\n"
     ]
    }
   ],
   "source": [
    "# Self-Correction Example\n",
    "# This query might trigger self-correction due to domain ambiguity\n",
    "\n",
    "correction_query = \"How do attention mechanisms differ between NLP and vision applications?\"\n",
    "\n",
    "print(f\"Query: {correction_query}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nRunning Advanced RAG with potential self-correction...\\n\")\n",
    "\n",
    "initial_state = {\n",
    "    \"user_question\": correction_query,\n",
    "    \"baseline_query\": correction_query,\n",
    "    \"messages\": [],\n",
    "    \"retrieved_docs\": [],\n",
    "    \"retrieval_attempts\": 0,\n",
    "    \"query_expansions\": [],\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-selfcorrect\"}}\n",
    "\n",
    "result = advanced_rag_graph.invoke(initial_state, config=config)\n",
    "\n",
    "# Display self-correction trace\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"EXECUTION TRACE\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Retrieval Attempts: {result.get('retrieval_attempts', 1)}\")\n",
    "print(f\"Strategy Used: {result.get('retrieval_strategy', 'semantic')}\")\n",
    "\n",
    "if result.get('strategy_changed'):\n",
    "    print(f\"Strategy Changed: Yes\")\n",
    "    print(f\"  Reason: {result.get('strategy_switch_reason', 'N/A')}\")\n",
    "\n",
    "quality = result.get('retrieval_quality_score', 0) or 0\n",
    "print(f\"Final Retrieval Quality: {quality:.0%}\")\n",
    "\n",
    "if result.get('retrieval_quality_issues'):\n",
    "    print(f\"Issues Detected: {', '.join(result['retrieval_quality_issues'])}\")\n",
    "\n",
    "if result.get('retrieval_improvement_suggestion'):\n",
    "    print(f\"Improvement Suggestion: {result['retrieval_improvement_suggestion']}\")\n",
    "\n",
    "print(f\"\\nGeneration Attempts: {result.get('generation_attempts', 1)}\")\n",
    "print(f\"Groundedness: {(result.get('groundedness_score', 0) or 0):.0%}\")\n",
    "print(f\"Answer Sufficient: {result.get('is_answer_sufficient', True)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"-\"*40)\n",
    "print(result.get('final_answer', 'No answer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11-metrics",
   "metadata": {},
   "source": [
    "## Evaluation Metrics Summary\n",
    "\n",
    "All tiers use **budget models** (GPT-4o-mini only) to isolate architectural improvements from model quality.\n",
    "\n",
    "### Standard Dataset (20 questions, k=4)\n",
    "\n",
    "| Tier | Precision@4 | Recall@4 | F1@4 | MRR | nDCG@4 |\n",
    "|------|-------------|----------|------|-----|--------|\n",
    "| Basic | 10.0% | 23.8% | 13.1% | 0.204 | 0.191 |\n",
    "| Intermediate | 17.5% | 40.0% | 23.0% | 0.425 | 0.384 |\n",
    "| Advanced | 20.0% | 43.3% | 25.9% | 0.550 | 0.443 |\n",
    "| **Multi-Agent** | **23.8%** | **47.1%** | **29.6%** | **0.558** | **0.464** |\n",
    "\n",
    "### Hard Dataset (10 questions, k=6, multi-document)\n",
    "\n",
    "| Tier | Precision@6 | Recall@6 | F1@6 | MRR | nDCG@6 |\n",
    "|------|-------------|----------|------|-----|--------|\n",
    "| Basic | 25.0% | 35.6% | 29.0% | 0.553 | 0.365 |\n",
    "| Intermediate | 23.3% | 33.1% | 27.0% | 0.533 | 0.358 |\n",
    "| Advanced | 28.3% | 38.4% | 32.1% | 0.600 | 0.422 |\n",
    "| **Multi-Agent** | **31.7%** | **42.3%** | **35.7%** | **0.667** | **0.464** |\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **2.3x retrieval accuracy** (F1@4: 13.1% -> 29.6%) with budget models only\n",
    "- Multi-Agent shows +30% improvement over Basic on complex queries\n",
    "- Query decomposition helps find relevant documents across multiple aspects\n",
    "- Architecture provides value independent of model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13-conclusion",
   "metadata": {},
   "source": "## Conclusion\n\n### Key Takeaways\n\n1. **Architecture > Model Size** - The graph structure provides value independent of model quality. Budget tier demonstrates the RAG intelligence; higher tiers add polish.\n\n2. **Distributed Decision-Making** - No central orchestrator. The StateGraph itself is the agent, with routing functions encoding planning logic.\n\n3. **Quality-Driven Flow** - Every routing point evaluates results and decides next action. Poor retrieval triggers correction; poor generation triggers retry.\n\n4. **Multi-Agent for Complexity** - Query decomposition with parallel workers significantly improves retrieval on complex, multi-faceted questions.\n\n### Source Code\n\n```\nsrc/advanced_agentic_rag_langgraph/\n    core/              # State, model tiers, retriever setup\n    evaluation/        # Metrics framework (F1, MRR, nDCG)\n    orchestration/     # Main graph, nodes, routing\n    retrieval/         # Strategy selection, reranking\n    validation/        # HHEM hallucination detection\n    variants/          # Basic, Intermediate, Advanced, Multi-Agent\n```"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced-agentic-rag-langgraph (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}